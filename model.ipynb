{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a60368c",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e521f808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, recall_score, precision_score, f1_score,auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "X = pd.read_csv('datasets/X.csv')\n",
    "y = pd.read_csv('datasets/y.csv')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ba82d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(),\n",
    "    \"LightGBM\": LGBMClassifier(),\n",
    "    \"CatBoost\": CatBoostClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91cbfb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7990, number of negative: 28010\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015895 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1154\n",
      "[LightGBM] [Info] Number of data points in the train set: 36000, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "Learning rate set to 0.047586\n",
      "0:\tlearn: 0.5924280\ttotal: 55.4ms\tremaining: 55.3s\n",
      "1:\tlearn: 0.5175471\ttotal: 104ms\tremaining: 52s\n",
      "2:\tlearn: 0.4564007\ttotal: 157ms\tremaining: 52.3s\n",
      "3:\tlearn: 0.4055148\ttotal: 204ms\tremaining: 50.7s\n",
      "4:\tlearn: 0.3666932\ttotal: 253ms\tremaining: 50.3s\n",
      "5:\tlearn: 0.3349120\ttotal: 304ms\tremaining: 50.3s\n",
      "6:\tlearn: 0.3132873\ttotal: 339ms\tremaining: 48.1s\n",
      "7:\tlearn: 0.2969559\ttotal: 364ms\tremaining: 45.1s\n",
      "8:\tlearn: 0.2849831\ttotal: 386ms\tremaining: 42.5s\n",
      "9:\tlearn: 0.2739826\ttotal: 412ms\tremaining: 40.8s\n",
      "10:\tlearn: 0.2644999\ttotal: 439ms\tremaining: 39.4s\n",
      "11:\tlearn: 0.2569997\ttotal: 469ms\tremaining: 38.6s\n",
      "12:\tlearn: 0.2505942\ttotal: 495ms\tremaining: 37.6s\n",
      "13:\tlearn: 0.2451614\ttotal: 518ms\tremaining: 36.5s\n",
      "14:\tlearn: 0.2398711\ttotal: 545ms\tremaining: 35.8s\n",
      "15:\tlearn: 0.2357046\ttotal: 566ms\tremaining: 34.8s\n",
      "16:\tlearn: 0.2323765\ttotal: 586ms\tremaining: 33.9s\n",
      "17:\tlearn: 0.2294030\ttotal: 609ms\tremaining: 33.2s\n",
      "18:\tlearn: 0.2267761\ttotal: 633ms\tremaining: 32.7s\n",
      "19:\tlearn: 0.2245404\ttotal: 660ms\tremaining: 32.3s\n",
      "20:\tlearn: 0.2225483\ttotal: 687ms\tremaining: 32s\n",
      "21:\tlearn: 0.2200049\ttotal: 709ms\tremaining: 31.5s\n",
      "22:\tlearn: 0.2182306\ttotal: 733ms\tremaining: 31.2s\n",
      "23:\tlearn: 0.2162070\ttotal: 757ms\tremaining: 30.8s\n",
      "24:\tlearn: 0.2142454\ttotal: 779ms\tremaining: 30.4s\n",
      "25:\tlearn: 0.2124711\ttotal: 800ms\tremaining: 30s\n",
      "26:\tlearn: 0.2107893\ttotal: 826ms\tremaining: 29.8s\n",
      "27:\tlearn: 0.2096113\ttotal: 848ms\tremaining: 29.4s\n",
      "28:\tlearn: 0.2085100\ttotal: 873ms\tremaining: 29.2s\n",
      "29:\tlearn: 0.2073423\ttotal: 894ms\tremaining: 28.9s\n",
      "30:\tlearn: 0.2062952\ttotal: 915ms\tremaining: 28.6s\n",
      "31:\tlearn: 0.2052037\ttotal: 940ms\tremaining: 28.4s\n",
      "32:\tlearn: 0.2039881\ttotal: 965ms\tremaining: 28.3s\n",
      "33:\tlearn: 0.2026448\ttotal: 990ms\tremaining: 28.1s\n",
      "34:\tlearn: 0.2018193\ttotal: 1.01s\tremaining: 27.9s\n",
      "35:\tlearn: 0.2006817\ttotal: 1.04s\tremaining: 27.7s\n",
      "36:\tlearn: 0.1999713\ttotal: 1.06s\tremaining: 27.6s\n",
      "37:\tlearn: 0.1992955\ttotal: 1.09s\tremaining: 27.7s\n",
      "38:\tlearn: 0.1982582\ttotal: 1.12s\tremaining: 27.6s\n",
      "39:\tlearn: 0.1974631\ttotal: 1.14s\tremaining: 27.4s\n",
      "40:\tlearn: 0.1960823\ttotal: 1.16s\tremaining: 27.2s\n",
      "41:\tlearn: 0.1952338\ttotal: 1.19s\tremaining: 27.1s\n",
      "42:\tlearn: 0.1945573\ttotal: 1.21s\tremaining: 26.9s\n",
      "43:\tlearn: 0.1939642\ttotal: 1.23s\tremaining: 26.8s\n",
      "44:\tlearn: 0.1933047\ttotal: 1.26s\tremaining: 26.7s\n",
      "45:\tlearn: 0.1927206\ttotal: 1.29s\tremaining: 26.7s\n",
      "46:\tlearn: 0.1921800\ttotal: 1.31s\tremaining: 26.6s\n",
      "47:\tlearn: 0.1917187\ttotal: 1.33s\tremaining: 26.5s\n",
      "48:\tlearn: 0.1910086\ttotal: 1.36s\tremaining: 26.3s\n",
      "49:\tlearn: 0.1898834\ttotal: 1.38s\tremaining: 26.2s\n",
      "50:\tlearn: 0.1893248\ttotal: 1.4s\tremaining: 26.1s\n",
      "51:\tlearn: 0.1888319\ttotal: 1.43s\tremaining: 26s\n",
      "52:\tlearn: 0.1883977\ttotal: 1.45s\tremaining: 25.9s\n",
      "53:\tlearn: 0.1880483\ttotal: 1.47s\tremaining: 25.8s\n",
      "54:\tlearn: 0.1875691\ttotal: 1.49s\tremaining: 25.7s\n",
      "55:\tlearn: 0.1863358\ttotal: 1.52s\tremaining: 25.6s\n",
      "56:\tlearn: 0.1859988\ttotal: 1.54s\tremaining: 25.6s\n",
      "57:\tlearn: 0.1856293\ttotal: 1.57s\tremaining: 25.4s\n",
      "58:\tlearn: 0.1853263\ttotal: 1.59s\tremaining: 25.3s\n",
      "59:\tlearn: 0.1850896\ttotal: 1.61s\tremaining: 25.3s\n",
      "60:\tlearn: 0.1846344\ttotal: 1.63s\tremaining: 25.1s\n",
      "61:\tlearn: 0.1842377\ttotal: 1.65s\tremaining: 25s\n",
      "62:\tlearn: 0.1838864\ttotal: 1.68s\tremaining: 24.9s\n",
      "63:\tlearn: 0.1835476\ttotal: 1.7s\tremaining: 24.9s\n",
      "64:\tlearn: 0.1830171\ttotal: 1.72s\tremaining: 24.8s\n",
      "65:\tlearn: 0.1826895\ttotal: 1.75s\tremaining: 24.7s\n",
      "66:\tlearn: 0.1821442\ttotal: 1.77s\tremaining: 24.6s\n",
      "67:\tlearn: 0.1818083\ttotal: 1.79s\tremaining: 24.6s\n",
      "68:\tlearn: 0.1814703\ttotal: 1.81s\tremaining: 24.5s\n",
      "69:\tlearn: 0.1808534\ttotal: 1.84s\tremaining: 24.4s\n",
      "70:\tlearn: 0.1806009\ttotal: 1.86s\tremaining: 24.3s\n",
      "71:\tlearn: 0.1802898\ttotal: 1.88s\tremaining: 24.3s\n",
      "72:\tlearn: 0.1799011\ttotal: 1.9s\tremaining: 24.2s\n",
      "73:\tlearn: 0.1796485\ttotal: 1.93s\tremaining: 24.1s\n",
      "74:\tlearn: 0.1793459\ttotal: 1.95s\tremaining: 24.1s\n",
      "75:\tlearn: 0.1791333\ttotal: 1.98s\tremaining: 24.1s\n",
      "76:\tlearn: 0.1787600\ttotal: 2s\tremaining: 24s\n",
      "77:\tlearn: 0.1782457\ttotal: 2.02s\tremaining: 23.9s\n",
      "78:\tlearn: 0.1780451\ttotal: 2.04s\tremaining: 23.8s\n",
      "79:\tlearn: 0.1777447\ttotal: 2.06s\tremaining: 23.7s\n",
      "80:\tlearn: 0.1774474\ttotal: 2.08s\tremaining: 23.7s\n",
      "81:\tlearn: 0.1771630\ttotal: 2.11s\tremaining: 23.6s\n",
      "82:\tlearn: 0.1770236\ttotal: 2.13s\tremaining: 23.6s\n",
      "83:\tlearn: 0.1768389\ttotal: 2.16s\tremaining: 23.5s\n",
      "84:\tlearn: 0.1767153\ttotal: 2.18s\tremaining: 23.5s\n",
      "85:\tlearn: 0.1766361\ttotal: 2.21s\tremaining: 23.5s\n",
      "86:\tlearn: 0.1764500\ttotal: 2.23s\tremaining: 23.4s\n",
      "87:\tlearn: 0.1762823\ttotal: 2.25s\tremaining: 23.4s\n",
      "88:\tlearn: 0.1761284\ttotal: 2.29s\tremaining: 23.4s\n",
      "89:\tlearn: 0.1758245\ttotal: 2.31s\tremaining: 23.4s\n",
      "90:\tlearn: 0.1757198\ttotal: 2.33s\tremaining: 23.3s\n",
      "91:\tlearn: 0.1750850\ttotal: 2.36s\tremaining: 23.3s\n",
      "92:\tlearn: 0.1749763\ttotal: 2.38s\tremaining: 23.2s\n",
      "93:\tlearn: 0.1748363\ttotal: 2.41s\tremaining: 23.2s\n",
      "94:\tlearn: 0.1746166\ttotal: 2.43s\tremaining: 23.2s\n",
      "95:\tlearn: 0.1742913\ttotal: 2.45s\tremaining: 23.1s\n",
      "96:\tlearn: 0.1739200\ttotal: 2.48s\tremaining: 23.1s\n",
      "97:\tlearn: 0.1736835\ttotal: 2.5s\tremaining: 23s\n",
      "98:\tlearn: 0.1732974\ttotal: 2.52s\tremaining: 22.9s\n",
      "99:\tlearn: 0.1731112\ttotal: 2.54s\tremaining: 22.9s\n",
      "100:\tlearn: 0.1730102\ttotal: 2.57s\tremaining: 22.8s\n",
      "101:\tlearn: 0.1728858\ttotal: 2.59s\tremaining: 22.8s\n",
      "102:\tlearn: 0.1726708\ttotal: 2.61s\tremaining: 22.8s\n",
      "103:\tlearn: 0.1725745\ttotal: 2.64s\tremaining: 22.7s\n",
      "104:\tlearn: 0.1724204\ttotal: 2.66s\tremaining: 22.6s\n",
      "105:\tlearn: 0.1722316\ttotal: 2.68s\tremaining: 22.6s\n",
      "106:\tlearn: 0.1717769\ttotal: 2.7s\tremaining: 22.6s\n",
      "107:\tlearn: 0.1716294\ttotal: 2.73s\tremaining: 22.5s\n",
      "108:\tlearn: 0.1715479\ttotal: 2.75s\tremaining: 22.5s\n",
      "109:\tlearn: 0.1714204\ttotal: 2.77s\tremaining: 22.4s\n",
      "110:\tlearn: 0.1713036\ttotal: 2.79s\tremaining: 22.4s\n",
      "111:\tlearn: 0.1711721\ttotal: 2.82s\tremaining: 22.3s\n",
      "112:\tlearn: 0.1710750\ttotal: 2.84s\tremaining: 22.3s\n",
      "113:\tlearn: 0.1709320\ttotal: 2.87s\tremaining: 22.3s\n",
      "114:\tlearn: 0.1708452\ttotal: 2.89s\tremaining: 22.2s\n",
      "115:\tlearn: 0.1707625\ttotal: 2.91s\tremaining: 22.2s\n",
      "116:\tlearn: 0.1706608\ttotal: 2.93s\tremaining: 22.1s\n",
      "117:\tlearn: 0.1705425\ttotal: 2.96s\tremaining: 22.1s\n",
      "118:\tlearn: 0.1703661\ttotal: 2.98s\tremaining: 22.1s\n",
      "119:\tlearn: 0.1702030\ttotal: 3s\tremaining: 22s\n",
      "120:\tlearn: 0.1699842\ttotal: 3.02s\tremaining: 22s\n",
      "121:\tlearn: 0.1698133\ttotal: 3.04s\tremaining: 21.9s\n",
      "122:\tlearn: 0.1696404\ttotal: 3.07s\tremaining: 21.9s\n",
      "123:\tlearn: 0.1695196\ttotal: 3.1s\tremaining: 21.9s\n",
      "124:\tlearn: 0.1694116\ttotal: 3.12s\tremaining: 21.9s\n",
      "125:\tlearn: 0.1693079\ttotal: 3.14s\tremaining: 21.8s\n",
      "126:\tlearn: 0.1691859\ttotal: 3.17s\tremaining: 21.8s\n",
      "127:\tlearn: 0.1690941\ttotal: 3.19s\tremaining: 21.7s\n",
      "128:\tlearn: 0.1689798\ttotal: 3.21s\tremaining: 21.6s\n",
      "129:\tlearn: 0.1688995\ttotal: 3.23s\tremaining: 21.6s\n",
      "130:\tlearn: 0.1688220\ttotal: 3.25s\tremaining: 21.6s\n",
      "131:\tlearn: 0.1686793\ttotal: 3.27s\tremaining: 21.5s\n",
      "132:\tlearn: 0.1686236\ttotal: 3.3s\tremaining: 21.5s\n",
      "133:\tlearn: 0.1685680\ttotal: 3.32s\tremaining: 21.5s\n",
      "134:\tlearn: 0.1684443\ttotal: 3.35s\tremaining: 21.4s\n",
      "135:\tlearn: 0.1683095\ttotal: 3.37s\tremaining: 21.4s\n",
      "136:\tlearn: 0.1682053\ttotal: 3.39s\tremaining: 21.4s\n",
      "137:\tlearn: 0.1681339\ttotal: 3.42s\tremaining: 21.3s\n",
      "138:\tlearn: 0.1679799\ttotal: 3.44s\tremaining: 21.3s\n",
      "139:\tlearn: 0.1677158\ttotal: 3.46s\tremaining: 21.3s\n",
      "140:\tlearn: 0.1676355\ttotal: 3.48s\tremaining: 21.2s\n",
      "141:\tlearn: 0.1675358\ttotal: 3.51s\tremaining: 21.2s\n",
      "142:\tlearn: 0.1674642\ttotal: 3.53s\tremaining: 21.2s\n",
      "143:\tlearn: 0.1673117\ttotal: 3.56s\tremaining: 21.2s\n",
      "144:\tlearn: 0.1672067\ttotal: 3.58s\tremaining: 21.1s\n",
      "145:\tlearn: 0.1671473\ttotal: 3.6s\tremaining: 21.1s\n",
      "146:\tlearn: 0.1670873\ttotal: 3.62s\tremaining: 21s\n",
      "147:\tlearn: 0.1668442\ttotal: 3.65s\tremaining: 21s\n",
      "148:\tlearn: 0.1667285\ttotal: 3.67s\tremaining: 21s\n",
      "149:\tlearn: 0.1666121\ttotal: 3.69s\tremaining: 20.9s\n",
      "150:\tlearn: 0.1663767\ttotal: 3.72s\tremaining: 20.9s\n",
      "151:\tlearn: 0.1663235\ttotal: 3.74s\tremaining: 20.9s\n",
      "152:\tlearn: 0.1662360\ttotal: 3.77s\tremaining: 20.9s\n",
      "153:\tlearn: 0.1661407\ttotal: 3.79s\tremaining: 20.8s\n",
      "154:\tlearn: 0.1660379\ttotal: 3.82s\tremaining: 20.8s\n",
      "155:\tlearn: 0.1659735\ttotal: 3.84s\tremaining: 20.8s\n",
      "156:\tlearn: 0.1658490\ttotal: 3.87s\tremaining: 20.8s\n",
      "157:\tlearn: 0.1657302\ttotal: 3.89s\tremaining: 20.7s\n",
      "158:\tlearn: 0.1656431\ttotal: 3.91s\tremaining: 20.7s\n",
      "159:\tlearn: 0.1655965\ttotal: 3.95s\tremaining: 20.7s\n",
      "160:\tlearn: 0.1654785\ttotal: 3.98s\tremaining: 20.7s\n",
      "161:\tlearn: 0.1653977\ttotal: 4s\tremaining: 20.7s\n",
      "162:\tlearn: 0.1652832\ttotal: 4.03s\tremaining: 20.7s\n",
      "163:\tlearn: 0.1651588\ttotal: 4.06s\tremaining: 20.7s\n",
      "164:\tlearn: 0.1650702\ttotal: 4.09s\tremaining: 20.7s\n",
      "165:\tlearn: 0.1649525\ttotal: 4.12s\tremaining: 20.7s\n",
      "166:\tlearn: 0.1648819\ttotal: 4.14s\tremaining: 20.6s\n",
      "167:\tlearn: 0.1648145\ttotal: 4.16s\tremaining: 20.6s\n",
      "168:\tlearn: 0.1646963\ttotal: 4.19s\tremaining: 20.6s\n",
      "169:\tlearn: 0.1645705\ttotal: 4.22s\tremaining: 20.6s\n",
      "170:\tlearn: 0.1644302\ttotal: 4.24s\tremaining: 20.6s\n",
      "171:\tlearn: 0.1643461\ttotal: 4.26s\tremaining: 20.5s\n",
      "172:\tlearn: 0.1643113\ttotal: 4.29s\tremaining: 20.5s\n",
      "173:\tlearn: 0.1641615\ttotal: 4.31s\tremaining: 20.5s\n",
      "174:\tlearn: 0.1640299\ttotal: 4.33s\tremaining: 20.4s\n",
      "175:\tlearn: 0.1639460\ttotal: 4.36s\tremaining: 20.4s\n",
      "176:\tlearn: 0.1638381\ttotal: 4.38s\tremaining: 20.4s\n",
      "177:\tlearn: 0.1637795\ttotal: 4.41s\tremaining: 20.4s\n",
      "178:\tlearn: 0.1637313\ttotal: 4.43s\tremaining: 20.3s\n",
      "179:\tlearn: 0.1635600\ttotal: 4.46s\tremaining: 20.3s\n",
      "180:\tlearn: 0.1635099\ttotal: 4.48s\tremaining: 20.3s\n",
      "181:\tlearn: 0.1634506\ttotal: 4.5s\tremaining: 20.2s\n",
      "182:\tlearn: 0.1633692\ttotal: 4.53s\tremaining: 20.2s\n",
      "183:\tlearn: 0.1633000\ttotal: 4.55s\tremaining: 20.2s\n",
      "184:\tlearn: 0.1631606\ttotal: 4.57s\tremaining: 20.1s\n",
      "185:\tlearn: 0.1630405\ttotal: 4.6s\tremaining: 20.1s\n",
      "186:\tlearn: 0.1628715\ttotal: 4.63s\tremaining: 20.1s\n",
      "187:\tlearn: 0.1627519\ttotal: 4.65s\tremaining: 20.1s\n",
      "188:\tlearn: 0.1627026\ttotal: 4.67s\tremaining: 20.1s\n",
      "189:\tlearn: 0.1625978\ttotal: 4.7s\tremaining: 20s\n",
      "190:\tlearn: 0.1625545\ttotal: 4.72s\tremaining: 20s\n",
      "191:\tlearn: 0.1623201\ttotal: 4.74s\tremaining: 20s\n",
      "192:\tlearn: 0.1622388\ttotal: 4.76s\tremaining: 19.9s\n",
      "193:\tlearn: 0.1621128\ttotal: 4.79s\tremaining: 19.9s\n",
      "194:\tlearn: 0.1620450\ttotal: 4.82s\tremaining: 19.9s\n",
      "195:\tlearn: 0.1619703\ttotal: 4.84s\tremaining: 19.9s\n",
      "196:\tlearn: 0.1618514\ttotal: 4.87s\tremaining: 19.8s\n",
      "197:\tlearn: 0.1617797\ttotal: 4.88s\tremaining: 19.8s\n",
      "198:\tlearn: 0.1616956\ttotal: 4.91s\tremaining: 19.8s\n",
      "199:\tlearn: 0.1615868\ttotal: 4.93s\tremaining: 19.7s\n",
      "200:\tlearn: 0.1614345\ttotal: 4.96s\tremaining: 19.7s\n",
      "201:\tlearn: 0.1613454\ttotal: 4.98s\tremaining: 19.7s\n",
      "202:\tlearn: 0.1612402\ttotal: 5s\tremaining: 19.6s\n",
      "203:\tlearn: 0.1611774\ttotal: 5.02s\tremaining: 19.6s\n",
      "204:\tlearn: 0.1610890\ttotal: 5.05s\tremaining: 19.6s\n",
      "205:\tlearn: 0.1609885\ttotal: 5.13s\tremaining: 19.8s\n",
      "206:\tlearn: 0.1609182\ttotal: 5.21s\tremaining: 20s\n",
      "207:\tlearn: 0.1608333\ttotal: 5.34s\tremaining: 20.3s\n",
      "208:\tlearn: 0.1607381\ttotal: 5.38s\tremaining: 20.4s\n",
      "209:\tlearn: 0.1606853\ttotal: 5.4s\tremaining: 20.3s\n",
      "210:\tlearn: 0.1606275\ttotal: 5.45s\tremaining: 20.4s\n",
      "211:\tlearn: 0.1604732\ttotal: 5.5s\tremaining: 20.4s\n",
      "212:\tlearn: 0.1603880\ttotal: 5.56s\tremaining: 20.5s\n",
      "213:\tlearn: 0.1602567\ttotal: 5.61s\tremaining: 20.6s\n",
      "214:\tlearn: 0.1601187\ttotal: 5.64s\tremaining: 20.6s\n",
      "215:\tlearn: 0.1600804\ttotal: 5.67s\tremaining: 20.6s\n",
      "216:\tlearn: 0.1599808\ttotal: 5.7s\tremaining: 20.6s\n",
      "217:\tlearn: 0.1598566\ttotal: 5.73s\tremaining: 20.6s\n",
      "218:\tlearn: 0.1597674\ttotal: 5.77s\tremaining: 20.6s\n",
      "219:\tlearn: 0.1597084\ttotal: 5.8s\tremaining: 20.6s\n",
      "220:\tlearn: 0.1596192\ttotal: 5.82s\tremaining: 20.5s\n",
      "221:\tlearn: 0.1595426\ttotal: 5.85s\tremaining: 20.5s\n",
      "222:\tlearn: 0.1594598\ttotal: 5.87s\tremaining: 20.4s\n",
      "223:\tlearn: 0.1593674\ttotal: 5.89s\tremaining: 20.4s\n",
      "224:\tlearn: 0.1593015\ttotal: 5.91s\tremaining: 20.4s\n",
      "225:\tlearn: 0.1592481\ttotal: 5.94s\tremaining: 20.3s\n",
      "226:\tlearn: 0.1591759\ttotal: 5.96s\tremaining: 20.3s\n",
      "227:\tlearn: 0.1590845\ttotal: 5.98s\tremaining: 20.3s\n",
      "228:\tlearn: 0.1590318\ttotal: 6.01s\tremaining: 20.2s\n",
      "229:\tlearn: 0.1589221\ttotal: 6.03s\tremaining: 20.2s\n",
      "230:\tlearn: 0.1588638\ttotal: 6.05s\tremaining: 20.2s\n",
      "231:\tlearn: 0.1587896\ttotal: 6.08s\tremaining: 20.1s\n",
      "232:\tlearn: 0.1587215\ttotal: 6.1s\tremaining: 20.1s\n",
      "233:\tlearn: 0.1586853\ttotal: 6.12s\tremaining: 20s\n",
      "234:\tlearn: 0.1585978\ttotal: 6.14s\tremaining: 20s\n",
      "235:\tlearn: 0.1585303\ttotal: 6.16s\tremaining: 19.9s\n",
      "236:\tlearn: 0.1584592\ttotal: 6.18s\tremaining: 19.9s\n",
      "237:\tlearn: 0.1581751\ttotal: 6.2s\tremaining: 19.9s\n",
      "238:\tlearn: 0.1581242\ttotal: 6.23s\tremaining: 19.8s\n",
      "239:\tlearn: 0.1580393\ttotal: 6.25s\tremaining: 19.8s\n",
      "240:\tlearn: 0.1578708\ttotal: 6.28s\tremaining: 19.8s\n",
      "241:\tlearn: 0.1578182\ttotal: 6.3s\tremaining: 19.7s\n",
      "242:\tlearn: 0.1577802\ttotal: 6.32s\tremaining: 19.7s\n",
      "243:\tlearn: 0.1576749\ttotal: 6.34s\tremaining: 19.6s\n",
      "244:\tlearn: 0.1575972\ttotal: 6.36s\tremaining: 19.6s\n",
      "245:\tlearn: 0.1574660\ttotal: 6.39s\tremaining: 19.6s\n",
      "246:\tlearn: 0.1573636\ttotal: 6.41s\tremaining: 19.5s\n",
      "247:\tlearn: 0.1573020\ttotal: 6.43s\tremaining: 19.5s\n",
      "248:\tlearn: 0.1572493\ttotal: 6.45s\tremaining: 19.5s\n",
      "249:\tlearn: 0.1571646\ttotal: 6.48s\tremaining: 19.4s\n",
      "250:\tlearn: 0.1571270\ttotal: 6.5s\tremaining: 19.4s\n",
      "251:\tlearn: 0.1570448\ttotal: 6.52s\tremaining: 19.4s\n",
      "252:\tlearn: 0.1569778\ttotal: 6.54s\tremaining: 19.3s\n",
      "253:\tlearn: 0.1568076\ttotal: 6.57s\tremaining: 19.3s\n",
      "254:\tlearn: 0.1567334\ttotal: 6.59s\tremaining: 19.3s\n",
      "255:\tlearn: 0.1566594\ttotal: 6.61s\tremaining: 19.2s\n",
      "256:\tlearn: 0.1565519\ttotal: 6.63s\tremaining: 19.2s\n",
      "257:\tlearn: 0.1564704\ttotal: 6.66s\tremaining: 19.2s\n",
      "258:\tlearn: 0.1563286\ttotal: 6.68s\tremaining: 19.1s\n",
      "259:\tlearn: 0.1562732\ttotal: 6.71s\tremaining: 19.1s\n",
      "260:\tlearn: 0.1561972\ttotal: 6.73s\tremaining: 19s\n",
      "261:\tlearn: 0.1561265\ttotal: 6.75s\tremaining: 19s\n",
      "262:\tlearn: 0.1560520\ttotal: 6.77s\tremaining: 19s\n",
      "263:\tlearn: 0.1559551\ttotal: 6.79s\tremaining: 18.9s\n",
      "264:\tlearn: 0.1558617\ttotal: 6.82s\tremaining: 18.9s\n",
      "265:\tlearn: 0.1558068\ttotal: 6.84s\tremaining: 18.9s\n",
      "266:\tlearn: 0.1557293\ttotal: 6.86s\tremaining: 18.8s\n",
      "267:\tlearn: 0.1555879\ttotal: 6.89s\tremaining: 18.8s\n",
      "268:\tlearn: 0.1555206\ttotal: 6.91s\tremaining: 18.8s\n",
      "269:\tlearn: 0.1554446\ttotal: 6.93s\tremaining: 18.7s\n",
      "270:\tlearn: 0.1553851\ttotal: 6.96s\tremaining: 18.7s\n",
      "271:\tlearn: 0.1552549\ttotal: 6.98s\tremaining: 18.7s\n",
      "272:\tlearn: 0.1551226\ttotal: 7s\tremaining: 18.7s\n",
      "273:\tlearn: 0.1550846\ttotal: 7.02s\tremaining: 18.6s\n",
      "274:\tlearn: 0.1549666\ttotal: 7.04s\tremaining: 18.6s\n",
      "275:\tlearn: 0.1548614\ttotal: 7.07s\tremaining: 18.5s\n",
      "276:\tlearn: 0.1547801\ttotal: 7.09s\tremaining: 18.5s\n",
      "277:\tlearn: 0.1547203\ttotal: 7.12s\tremaining: 18.5s\n",
      "278:\tlearn: 0.1546328\ttotal: 7.14s\tremaining: 18.4s\n",
      "279:\tlearn: 0.1545689\ttotal: 7.16s\tremaining: 18.4s\n",
      "280:\tlearn: 0.1544805\ttotal: 7.18s\tremaining: 18.4s\n",
      "281:\tlearn: 0.1544353\ttotal: 7.2s\tremaining: 18.3s\n",
      "282:\tlearn: 0.1543076\ttotal: 7.23s\tremaining: 18.3s\n",
      "283:\tlearn: 0.1542440\ttotal: 7.25s\tremaining: 18.3s\n",
      "284:\tlearn: 0.1540868\ttotal: 7.27s\tremaining: 18.2s\n",
      "285:\tlearn: 0.1540115\ttotal: 7.32s\tremaining: 18.3s\n",
      "286:\tlearn: 0.1539710\ttotal: 7.35s\tremaining: 18.3s\n",
      "287:\tlearn: 0.1538766\ttotal: 7.37s\tremaining: 18.2s\n",
      "288:\tlearn: 0.1537509\ttotal: 7.4s\tremaining: 18.2s\n",
      "289:\tlearn: 0.1536448\ttotal: 7.42s\tremaining: 18.2s\n",
      "290:\tlearn: 0.1535764\ttotal: 7.44s\tremaining: 18.1s\n",
      "291:\tlearn: 0.1535271\ttotal: 7.47s\tremaining: 18.1s\n",
      "292:\tlearn: 0.1534613\ttotal: 7.49s\tremaining: 18.1s\n",
      "293:\tlearn: 0.1534164\ttotal: 7.52s\tremaining: 18s\n",
      "294:\tlearn: 0.1533294\ttotal: 7.54s\tremaining: 18s\n",
      "295:\tlearn: 0.1532725\ttotal: 7.56s\tremaining: 18s\n",
      "296:\tlearn: 0.1531645\ttotal: 7.58s\tremaining: 17.9s\n",
      "297:\tlearn: 0.1531131\ttotal: 7.6s\tremaining: 17.9s\n",
      "298:\tlearn: 0.1529514\ttotal: 7.62s\tremaining: 17.9s\n",
      "299:\tlearn: 0.1527926\ttotal: 7.65s\tremaining: 17.8s\n",
      "300:\tlearn: 0.1527102\ttotal: 7.67s\tremaining: 17.8s\n",
      "301:\tlearn: 0.1526400\ttotal: 7.69s\tremaining: 17.8s\n",
      "302:\tlearn: 0.1525270\ttotal: 7.72s\tremaining: 17.8s\n",
      "303:\tlearn: 0.1524708\ttotal: 7.74s\tremaining: 17.7s\n",
      "304:\tlearn: 0.1523911\ttotal: 7.76s\tremaining: 17.7s\n",
      "305:\tlearn: 0.1523248\ttotal: 7.78s\tremaining: 17.7s\n",
      "306:\tlearn: 0.1522563\ttotal: 7.8s\tremaining: 17.6s\n",
      "307:\tlearn: 0.1521850\ttotal: 7.83s\tremaining: 17.6s\n",
      "308:\tlearn: 0.1521194\ttotal: 7.85s\tremaining: 17.6s\n",
      "309:\tlearn: 0.1520694\ttotal: 7.87s\tremaining: 17.5s\n",
      "310:\tlearn: 0.1519037\ttotal: 7.89s\tremaining: 17.5s\n",
      "311:\tlearn: 0.1518313\ttotal: 7.92s\tremaining: 17.5s\n",
      "312:\tlearn: 0.1516575\ttotal: 7.94s\tremaining: 17.4s\n",
      "313:\tlearn: 0.1515726\ttotal: 7.97s\tremaining: 17.4s\n",
      "314:\tlearn: 0.1514940\ttotal: 7.99s\tremaining: 17.4s\n",
      "315:\tlearn: 0.1514389\ttotal: 8.01s\tremaining: 17.3s\n",
      "316:\tlearn: 0.1513581\ttotal: 8.03s\tremaining: 17.3s\n",
      "317:\tlearn: 0.1512468\ttotal: 8.05s\tremaining: 17.3s\n",
      "318:\tlearn: 0.1511950\ttotal: 8.08s\tremaining: 17.2s\n",
      "319:\tlearn: 0.1511346\ttotal: 8.1s\tremaining: 17.2s\n",
      "320:\tlearn: 0.1510509\ttotal: 8.12s\tremaining: 17.2s\n",
      "321:\tlearn: 0.1509770\ttotal: 8.14s\tremaining: 17.2s\n",
      "322:\tlearn: 0.1509285\ttotal: 8.17s\tremaining: 17.1s\n",
      "323:\tlearn: 0.1508680\ttotal: 8.19s\tremaining: 17.1s\n",
      "324:\tlearn: 0.1508336\ttotal: 8.21s\tremaining: 17.1s\n",
      "325:\tlearn: 0.1507812\ttotal: 8.23s\tremaining: 17s\n",
      "326:\tlearn: 0.1507103\ttotal: 8.25s\tremaining: 17s\n",
      "327:\tlearn: 0.1506121\ttotal: 8.28s\tremaining: 17s\n",
      "328:\tlearn: 0.1504961\ttotal: 8.3s\tremaining: 16.9s\n",
      "329:\tlearn: 0.1504620\ttotal: 8.32s\tremaining: 16.9s\n",
      "330:\tlearn: 0.1504191\ttotal: 8.34s\tremaining: 16.9s\n",
      "331:\tlearn: 0.1503624\ttotal: 8.36s\tremaining: 16.8s\n",
      "332:\tlearn: 0.1502688\ttotal: 8.39s\tremaining: 16.8s\n",
      "333:\tlearn: 0.1502034\ttotal: 8.41s\tremaining: 16.8s\n",
      "334:\tlearn: 0.1500901\ttotal: 8.43s\tremaining: 16.7s\n",
      "335:\tlearn: 0.1499669\ttotal: 8.46s\tremaining: 16.7s\n",
      "336:\tlearn: 0.1498498\ttotal: 8.48s\tremaining: 16.7s\n",
      "337:\tlearn: 0.1497777\ttotal: 8.5s\tremaining: 16.6s\n",
      "338:\tlearn: 0.1497238\ttotal: 8.52s\tremaining: 16.6s\n",
      "339:\tlearn: 0.1496314\ttotal: 8.54s\tremaining: 16.6s\n",
      "340:\tlearn: 0.1495614\ttotal: 8.57s\tremaining: 16.6s\n",
      "341:\tlearn: 0.1495122\ttotal: 8.59s\tremaining: 16.5s\n",
      "342:\tlearn: 0.1494723\ttotal: 8.61s\tremaining: 16.5s\n",
      "343:\tlearn: 0.1494063\ttotal: 8.63s\tremaining: 16.5s\n",
      "344:\tlearn: 0.1493419\ttotal: 8.65s\tremaining: 16.4s\n",
      "345:\tlearn: 0.1492303\ttotal: 8.68s\tremaining: 16.4s\n",
      "346:\tlearn: 0.1491768\ttotal: 8.7s\tremaining: 16.4s\n",
      "347:\tlearn: 0.1490983\ttotal: 8.72s\tremaining: 16.3s\n",
      "348:\tlearn: 0.1490040\ttotal: 8.75s\tremaining: 16.3s\n",
      "349:\tlearn: 0.1489353\ttotal: 8.77s\tremaining: 16.3s\n",
      "350:\tlearn: 0.1488626\ttotal: 8.79s\tremaining: 16.3s\n",
      "351:\tlearn: 0.1488134\ttotal: 8.82s\tremaining: 16.2s\n",
      "352:\tlearn: 0.1487174\ttotal: 8.84s\tremaining: 16.2s\n",
      "353:\tlearn: 0.1486123\ttotal: 8.86s\tremaining: 16.2s\n",
      "354:\tlearn: 0.1485426\ttotal: 8.88s\tremaining: 16.1s\n",
      "355:\tlearn: 0.1484560\ttotal: 8.9s\tremaining: 16.1s\n",
      "356:\tlearn: 0.1484020\ttotal: 8.92s\tremaining: 16.1s\n",
      "357:\tlearn: 0.1483105\ttotal: 8.95s\tremaining: 16.1s\n",
      "358:\tlearn: 0.1482451\ttotal: 8.97s\tremaining: 16s\n",
      "359:\tlearn: 0.1481751\ttotal: 8.99s\tremaining: 16s\n",
      "360:\tlearn: 0.1480827\ttotal: 9.01s\tremaining: 16s\n",
      "361:\tlearn: 0.1480155\ttotal: 9.04s\tremaining: 15.9s\n",
      "362:\tlearn: 0.1479762\ttotal: 9.06s\tremaining: 15.9s\n",
      "363:\tlearn: 0.1478874\ttotal: 9.08s\tremaining: 15.9s\n",
      "364:\tlearn: 0.1478423\ttotal: 9.1s\tremaining: 15.8s\n",
      "365:\tlearn: 0.1477047\ttotal: 9.13s\tremaining: 15.8s\n",
      "366:\tlearn: 0.1476125\ttotal: 9.15s\tremaining: 15.8s\n",
      "367:\tlearn: 0.1475453\ttotal: 9.17s\tremaining: 15.7s\n",
      "368:\tlearn: 0.1475024\ttotal: 9.19s\tremaining: 15.7s\n",
      "369:\tlearn: 0.1473941\ttotal: 9.21s\tremaining: 15.7s\n",
      "370:\tlearn: 0.1472859\ttotal: 9.23s\tremaining: 15.7s\n",
      "371:\tlearn: 0.1472391\ttotal: 9.26s\tremaining: 15.6s\n",
      "372:\tlearn: 0.1471843\ttotal: 9.28s\tremaining: 15.6s\n",
      "373:\tlearn: 0.1471012\ttotal: 9.3s\tremaining: 15.6s\n",
      "374:\tlearn: 0.1470156\ttotal: 9.32s\tremaining: 15.5s\n",
      "375:\tlearn: 0.1469364\ttotal: 9.35s\tremaining: 15.5s\n",
      "376:\tlearn: 0.1468836\ttotal: 9.37s\tremaining: 15.5s\n",
      "377:\tlearn: 0.1468283\ttotal: 9.39s\tremaining: 15.5s\n",
      "378:\tlearn: 0.1467659\ttotal: 9.41s\tremaining: 15.4s\n",
      "379:\tlearn: 0.1466482\ttotal: 9.44s\tremaining: 15.4s\n",
      "380:\tlearn: 0.1464984\ttotal: 9.46s\tremaining: 15.4s\n",
      "381:\tlearn: 0.1464632\ttotal: 9.48s\tremaining: 15.3s\n",
      "382:\tlearn: 0.1463663\ttotal: 9.51s\tremaining: 15.3s\n",
      "383:\tlearn: 0.1463301\ttotal: 9.53s\tremaining: 15.3s\n",
      "384:\tlearn: 0.1462807\ttotal: 9.55s\tremaining: 15.3s\n",
      "385:\tlearn: 0.1462069\ttotal: 9.57s\tremaining: 15.2s\n",
      "386:\tlearn: 0.1461286\ttotal: 9.59s\tremaining: 15.2s\n",
      "387:\tlearn: 0.1460570\ttotal: 9.61s\tremaining: 15.2s\n",
      "388:\tlearn: 0.1460077\ttotal: 9.63s\tremaining: 15.1s\n",
      "389:\tlearn: 0.1459074\ttotal: 9.66s\tremaining: 15.1s\n",
      "390:\tlearn: 0.1458539\ttotal: 9.69s\tremaining: 15.1s\n",
      "391:\tlearn: 0.1457851\ttotal: 9.71s\tremaining: 15.1s\n",
      "392:\tlearn: 0.1457486\ttotal: 9.73s\tremaining: 15s\n",
      "393:\tlearn: 0.1456900\ttotal: 9.75s\tremaining: 15s\n",
      "394:\tlearn: 0.1456168\ttotal: 9.77s\tremaining: 15s\n",
      "395:\tlearn: 0.1455564\ttotal: 9.8s\tremaining: 14.9s\n",
      "396:\tlearn: 0.1455237\ttotal: 9.82s\tremaining: 14.9s\n",
      "397:\tlearn: 0.1454497\ttotal: 9.84s\tremaining: 14.9s\n",
      "398:\tlearn: 0.1453827\ttotal: 9.86s\tremaining: 14.9s\n",
      "399:\tlearn: 0.1453183\ttotal: 9.88s\tremaining: 14.8s\n",
      "400:\tlearn: 0.1451887\ttotal: 9.91s\tremaining: 14.8s\n",
      "401:\tlearn: 0.1451199\ttotal: 9.93s\tremaining: 14.8s\n",
      "402:\tlearn: 0.1450593\ttotal: 9.95s\tremaining: 14.7s\n",
      "403:\tlearn: 0.1450058\ttotal: 9.97s\tremaining: 14.7s\n",
      "404:\tlearn: 0.1449477\ttotal: 10s\tremaining: 14.7s\n",
      "405:\tlearn: 0.1448398\ttotal: 10s\tremaining: 14.7s\n",
      "406:\tlearn: 0.1447585\ttotal: 10s\tremaining: 14.6s\n",
      "407:\tlearn: 0.1446876\ttotal: 10.1s\tremaining: 14.6s\n",
      "408:\tlearn: 0.1446367\ttotal: 10.1s\tremaining: 14.6s\n",
      "409:\tlearn: 0.1445943\ttotal: 10.1s\tremaining: 14.6s\n",
      "410:\tlearn: 0.1445523\ttotal: 10.1s\tremaining: 14.5s\n",
      "411:\tlearn: 0.1444797\ttotal: 10.2s\tremaining: 14.5s\n",
      "412:\tlearn: 0.1444284\ttotal: 10.2s\tremaining: 14.5s\n",
      "413:\tlearn: 0.1443704\ttotal: 10.2s\tremaining: 14.4s\n",
      "414:\tlearn: 0.1443235\ttotal: 10.2s\tremaining: 14.4s\n",
      "415:\tlearn: 0.1442878\ttotal: 10.3s\tremaining: 14.4s\n",
      "416:\tlearn: 0.1442433\ttotal: 10.3s\tremaining: 14.4s\n",
      "417:\tlearn: 0.1442106\ttotal: 10.3s\tremaining: 14.3s\n",
      "418:\tlearn: 0.1441747\ttotal: 10.3s\tremaining: 14.3s\n",
      "419:\tlearn: 0.1441283\ttotal: 10.3s\tremaining: 14.3s\n",
      "420:\tlearn: 0.1440389\ttotal: 10.4s\tremaining: 14.3s\n",
      "421:\tlearn: 0.1440102\ttotal: 10.4s\tremaining: 14.2s\n",
      "422:\tlearn: 0.1439140\ttotal: 10.4s\tremaining: 14.2s\n",
      "423:\tlearn: 0.1438374\ttotal: 10.4s\tremaining: 14.2s\n",
      "424:\tlearn: 0.1437659\ttotal: 10.5s\tremaining: 14.1s\n",
      "425:\tlearn: 0.1437078\ttotal: 10.5s\tremaining: 14.1s\n",
      "426:\tlearn: 0.1436270\ttotal: 10.5s\tremaining: 14.1s\n",
      "427:\tlearn: 0.1435899\ttotal: 10.5s\tremaining: 14.1s\n",
      "428:\tlearn: 0.1435070\ttotal: 10.5s\tremaining: 14s\n",
      "429:\tlearn: 0.1434688\ttotal: 10.6s\tremaining: 14s\n",
      "430:\tlearn: 0.1434266\ttotal: 10.6s\tremaining: 14s\n",
      "431:\tlearn: 0.1433390\ttotal: 10.6s\tremaining: 14s\n",
      "432:\tlearn: 0.1432824\ttotal: 10.6s\tremaining: 13.9s\n",
      "433:\tlearn: 0.1431994\ttotal: 10.7s\tremaining: 13.9s\n",
      "434:\tlearn: 0.1431327\ttotal: 10.7s\tremaining: 13.9s\n",
      "435:\tlearn: 0.1430873\ttotal: 10.7s\tremaining: 13.8s\n",
      "436:\tlearn: 0.1430208\ttotal: 10.8s\tremaining: 13.9s\n",
      "437:\tlearn: 0.1429687\ttotal: 10.8s\tremaining: 13.9s\n",
      "438:\tlearn: 0.1429012\ttotal: 10.9s\tremaining: 13.9s\n",
      "439:\tlearn: 0.1428472\ttotal: 10.9s\tremaining: 13.9s\n",
      "440:\tlearn: 0.1427981\ttotal: 10.9s\tremaining: 13.9s\n",
      "441:\tlearn: 0.1426777\ttotal: 11s\tremaining: 13.8s\n",
      "442:\tlearn: 0.1426353\ttotal: 11s\tremaining: 13.8s\n",
      "443:\tlearn: 0.1425842\ttotal: 11s\tremaining: 13.8s\n",
      "444:\tlearn: 0.1425445\ttotal: 11s\tremaining: 13.8s\n",
      "445:\tlearn: 0.1424820\ttotal: 11.1s\tremaining: 13.7s\n",
      "446:\tlearn: 0.1424150\ttotal: 11.1s\tremaining: 13.7s\n",
      "447:\tlearn: 0.1423567\ttotal: 11.1s\tremaining: 13.7s\n",
      "448:\tlearn: 0.1423129\ttotal: 11.1s\tremaining: 13.7s\n",
      "449:\tlearn: 0.1422617\ttotal: 11.1s\tremaining: 13.6s\n",
      "450:\tlearn: 0.1422060\ttotal: 11.2s\tremaining: 13.6s\n",
      "451:\tlearn: 0.1421354\ttotal: 11.2s\tremaining: 13.6s\n",
      "452:\tlearn: 0.1420651\ttotal: 11.2s\tremaining: 13.5s\n",
      "453:\tlearn: 0.1419899\ttotal: 11.2s\tremaining: 13.5s\n",
      "454:\tlearn: 0.1419483\ttotal: 11.3s\tremaining: 13.5s\n",
      "455:\tlearn: 0.1418773\ttotal: 11.3s\tremaining: 13.5s\n",
      "456:\tlearn: 0.1418425\ttotal: 11.3s\tremaining: 13.4s\n",
      "457:\tlearn: 0.1417835\ttotal: 11.3s\tremaining: 13.4s\n",
      "458:\tlearn: 0.1417393\ttotal: 11.4s\tremaining: 13.4s\n",
      "459:\tlearn: 0.1416943\ttotal: 11.4s\tremaining: 13.3s\n",
      "460:\tlearn: 0.1416607\ttotal: 11.4s\tremaining: 13.3s\n",
      "461:\tlearn: 0.1416182\ttotal: 11.4s\tremaining: 13.3s\n",
      "462:\tlearn: 0.1415459\ttotal: 11.5s\tremaining: 13.3s\n",
      "463:\tlearn: 0.1415131\ttotal: 11.5s\tremaining: 13.3s\n",
      "464:\tlearn: 0.1414666\ttotal: 11.5s\tremaining: 13.2s\n",
      "465:\tlearn: 0.1414071\ttotal: 11.5s\tremaining: 13.2s\n",
      "466:\tlearn: 0.1412975\ttotal: 11.5s\tremaining: 13.2s\n",
      "467:\tlearn: 0.1412298\ttotal: 11.6s\tremaining: 13.2s\n",
      "468:\tlearn: 0.1411675\ttotal: 11.6s\tremaining: 13.1s\n",
      "469:\tlearn: 0.1411164\ttotal: 11.6s\tremaining: 13.1s\n",
      "470:\tlearn: 0.1410514\ttotal: 11.6s\tremaining: 13.1s\n",
      "471:\tlearn: 0.1409957\ttotal: 11.7s\tremaining: 13s\n",
      "472:\tlearn: 0.1409400\ttotal: 11.7s\tremaining: 13s\n",
      "473:\tlearn: 0.1408839\ttotal: 11.7s\tremaining: 13s\n",
      "474:\tlearn: 0.1408521\ttotal: 11.7s\tremaining: 13s\n",
      "475:\tlearn: 0.1407876\ttotal: 11.8s\tremaining: 12.9s\n",
      "476:\tlearn: 0.1407301\ttotal: 11.8s\tremaining: 12.9s\n",
      "477:\tlearn: 0.1406873\ttotal: 11.8s\tremaining: 12.9s\n",
      "478:\tlearn: 0.1406093\ttotal: 11.8s\tremaining: 12.9s\n",
      "479:\tlearn: 0.1405735\ttotal: 11.8s\tremaining: 12.8s\n",
      "480:\tlearn: 0.1405180\ttotal: 11.9s\tremaining: 12.8s\n",
      "481:\tlearn: 0.1404752\ttotal: 11.9s\tremaining: 12.8s\n",
      "482:\tlearn: 0.1404083\ttotal: 11.9s\tremaining: 12.8s\n",
      "483:\tlearn: 0.1403586\ttotal: 11.9s\tremaining: 12.7s\n",
      "484:\tlearn: 0.1403329\ttotal: 12s\tremaining: 12.7s\n",
      "485:\tlearn: 0.1402910\ttotal: 12s\tremaining: 12.7s\n",
      "486:\tlearn: 0.1402349\ttotal: 12s\tremaining: 12.7s\n",
      "487:\tlearn: 0.1401697\ttotal: 12.1s\tremaining: 12.6s\n",
      "488:\tlearn: 0.1400993\ttotal: 12.1s\tremaining: 12.6s\n",
      "489:\tlearn: 0.1400190\ttotal: 12.1s\tremaining: 12.6s\n",
      "490:\tlearn: 0.1399140\ttotal: 12.1s\tremaining: 12.6s\n",
      "491:\tlearn: 0.1398290\ttotal: 12.1s\tremaining: 12.5s\n",
      "492:\tlearn: 0.1397475\ttotal: 12.2s\tremaining: 12.5s\n",
      "493:\tlearn: 0.1396814\ttotal: 12.2s\tremaining: 12.5s\n",
      "494:\tlearn: 0.1396173\ttotal: 12.2s\tremaining: 12.5s\n",
      "495:\tlearn: 0.1395580\ttotal: 12.2s\tremaining: 12.4s\n",
      "496:\tlearn: 0.1395164\ttotal: 12.3s\tremaining: 12.4s\n",
      "497:\tlearn: 0.1394696\ttotal: 12.3s\tremaining: 12.4s\n",
      "498:\tlearn: 0.1393879\ttotal: 12.3s\tremaining: 12.4s\n",
      "499:\tlearn: 0.1393598\ttotal: 12.3s\tremaining: 12.3s\n",
      "500:\tlearn: 0.1392960\ttotal: 12.4s\tremaining: 12.3s\n",
      "501:\tlearn: 0.1392476\ttotal: 12.4s\tremaining: 12.3s\n",
      "502:\tlearn: 0.1391963\ttotal: 12.4s\tremaining: 12.3s\n",
      "503:\tlearn: 0.1391368\ttotal: 12.4s\tremaining: 12.2s\n",
      "504:\tlearn: 0.1391016\ttotal: 12.5s\tremaining: 12.2s\n",
      "505:\tlearn: 0.1390309\ttotal: 12.5s\tremaining: 12.2s\n",
      "506:\tlearn: 0.1389325\ttotal: 12.5s\tremaining: 12.2s\n",
      "507:\tlearn: 0.1388625\ttotal: 12.5s\tremaining: 12.1s\n",
      "508:\tlearn: 0.1388165\ttotal: 12.5s\tremaining: 12.1s\n",
      "509:\tlearn: 0.1387444\ttotal: 12.6s\tremaining: 12.1s\n",
      "510:\tlearn: 0.1386822\ttotal: 12.6s\tremaining: 12.1s\n",
      "511:\tlearn: 0.1386270\ttotal: 12.6s\tremaining: 12s\n",
      "512:\tlearn: 0.1385864\ttotal: 12.6s\tremaining: 12s\n",
      "513:\tlearn: 0.1385413\ttotal: 12.7s\tremaining: 12s\n",
      "514:\tlearn: 0.1385011\ttotal: 12.7s\tremaining: 11.9s\n",
      "515:\tlearn: 0.1384442\ttotal: 12.7s\tremaining: 11.9s\n",
      "516:\tlearn: 0.1383747\ttotal: 12.7s\tremaining: 11.9s\n",
      "517:\tlearn: 0.1383181\ttotal: 12.8s\tremaining: 11.9s\n",
      "518:\tlearn: 0.1382693\ttotal: 12.8s\tremaining: 11.8s\n",
      "519:\tlearn: 0.1381891\ttotal: 12.8s\tremaining: 11.8s\n",
      "520:\tlearn: 0.1381076\ttotal: 12.8s\tremaining: 11.8s\n",
      "521:\tlearn: 0.1380693\ttotal: 12.9s\tremaining: 11.8s\n",
      "522:\tlearn: 0.1380185\ttotal: 12.9s\tremaining: 11.7s\n",
      "523:\tlearn: 0.1379563\ttotal: 12.9s\tremaining: 11.7s\n",
      "524:\tlearn: 0.1379159\ttotal: 12.9s\tremaining: 11.7s\n",
      "525:\tlearn: 0.1378779\ttotal: 12.9s\tremaining: 11.7s\n",
      "526:\tlearn: 0.1378212\ttotal: 13s\tremaining: 11.6s\n",
      "527:\tlearn: 0.1377553\ttotal: 13s\tremaining: 11.6s\n",
      "528:\tlearn: 0.1376709\ttotal: 13s\tremaining: 11.6s\n",
      "529:\tlearn: 0.1376175\ttotal: 13s\tremaining: 11.6s\n",
      "530:\tlearn: 0.1375768\ttotal: 13.1s\tremaining: 11.5s\n",
      "531:\tlearn: 0.1375004\ttotal: 13.1s\tremaining: 11.5s\n",
      "532:\tlearn: 0.1374530\ttotal: 13.1s\tremaining: 11.5s\n",
      "533:\tlearn: 0.1374122\ttotal: 13.1s\tremaining: 11.5s\n",
      "534:\tlearn: 0.1373611\ttotal: 13.2s\tremaining: 11.4s\n",
      "535:\tlearn: 0.1373293\ttotal: 13.2s\tremaining: 11.4s\n",
      "536:\tlearn: 0.1373108\ttotal: 13.2s\tremaining: 11.4s\n",
      "537:\tlearn: 0.1372757\ttotal: 13.2s\tremaining: 11.4s\n",
      "538:\tlearn: 0.1372305\ttotal: 13.3s\tremaining: 11.3s\n",
      "539:\tlearn: 0.1371891\ttotal: 13.3s\tremaining: 11.3s\n",
      "540:\tlearn: 0.1371331\ttotal: 13.3s\tremaining: 11.3s\n",
      "541:\tlearn: 0.1370921\ttotal: 13.3s\tremaining: 11.3s\n",
      "542:\tlearn: 0.1370274\ttotal: 13.3s\tremaining: 11.2s\n",
      "543:\tlearn: 0.1369841\ttotal: 13.4s\tremaining: 11.2s\n",
      "544:\tlearn: 0.1369350\ttotal: 13.4s\tremaining: 11.2s\n",
      "545:\tlearn: 0.1368855\ttotal: 13.4s\tremaining: 11.1s\n",
      "546:\tlearn: 0.1368458\ttotal: 13.4s\tremaining: 11.1s\n",
      "547:\tlearn: 0.1367872\ttotal: 13.5s\tremaining: 11.1s\n",
      "548:\tlearn: 0.1367387\ttotal: 13.5s\tremaining: 11.1s\n",
      "549:\tlearn: 0.1367018\ttotal: 13.5s\tremaining: 11s\n",
      "550:\tlearn: 0.1366100\ttotal: 13.5s\tremaining: 11s\n",
      "551:\tlearn: 0.1365182\ttotal: 13.6s\tremaining: 11s\n",
      "552:\tlearn: 0.1364502\ttotal: 13.6s\tremaining: 11s\n",
      "553:\tlearn: 0.1364123\ttotal: 13.6s\tremaining: 10.9s\n",
      "554:\tlearn: 0.1363287\ttotal: 13.6s\tremaining: 10.9s\n",
      "555:\tlearn: 0.1362842\ttotal: 13.7s\tremaining: 10.9s\n",
      "556:\tlearn: 0.1362356\ttotal: 13.7s\tremaining: 10.9s\n",
      "557:\tlearn: 0.1362105\ttotal: 13.7s\tremaining: 10.8s\n",
      "558:\tlearn: 0.1361727\ttotal: 13.7s\tremaining: 10.8s\n",
      "559:\tlearn: 0.1361250\ttotal: 13.7s\tremaining: 10.8s\n",
      "560:\tlearn: 0.1360935\ttotal: 13.8s\tremaining: 10.8s\n",
      "561:\tlearn: 0.1360414\ttotal: 13.8s\tremaining: 10.8s\n",
      "562:\tlearn: 0.1360027\ttotal: 13.8s\tremaining: 10.7s\n",
      "563:\tlearn: 0.1359774\ttotal: 13.8s\tremaining: 10.7s\n",
      "564:\tlearn: 0.1358861\ttotal: 13.9s\tremaining: 10.7s\n",
      "565:\tlearn: 0.1358481\ttotal: 13.9s\tremaining: 10.7s\n",
      "566:\tlearn: 0.1357984\ttotal: 13.9s\tremaining: 10.6s\n",
      "567:\tlearn: 0.1357270\ttotal: 13.9s\tremaining: 10.6s\n",
      "568:\tlearn: 0.1356507\ttotal: 14s\tremaining: 10.6s\n",
      "569:\tlearn: 0.1356014\ttotal: 14s\tremaining: 10.6s\n",
      "570:\tlearn: 0.1355515\ttotal: 14s\tremaining: 10.5s\n",
      "571:\tlearn: 0.1354891\ttotal: 14s\tremaining: 10.5s\n",
      "572:\tlearn: 0.1354154\ttotal: 14.1s\tremaining: 10.5s\n",
      "573:\tlearn: 0.1353751\ttotal: 14.1s\tremaining: 10.5s\n",
      "574:\tlearn: 0.1353221\ttotal: 14.1s\tremaining: 10.4s\n",
      "575:\tlearn: 0.1352661\ttotal: 14.1s\tremaining: 10.4s\n",
      "576:\tlearn: 0.1352325\ttotal: 14.2s\tremaining: 10.4s\n",
      "577:\tlearn: 0.1351493\ttotal: 14.2s\tremaining: 10.4s\n",
      "578:\tlearn: 0.1350820\ttotal: 14.2s\tremaining: 10.3s\n",
      "579:\tlearn: 0.1350532\ttotal: 14.2s\tremaining: 10.3s\n",
      "580:\tlearn: 0.1349749\ttotal: 14.3s\tremaining: 10.3s\n",
      "581:\tlearn: 0.1349409\ttotal: 14.3s\tremaining: 10.3s\n",
      "582:\tlearn: 0.1348798\ttotal: 14.3s\tremaining: 10.2s\n",
      "583:\tlearn: 0.1348235\ttotal: 14.3s\tremaining: 10.2s\n",
      "584:\tlearn: 0.1347883\ttotal: 14.4s\tremaining: 10.2s\n",
      "585:\tlearn: 0.1347403\ttotal: 14.4s\tremaining: 10.2s\n",
      "586:\tlearn: 0.1346918\ttotal: 14.4s\tremaining: 10.1s\n",
      "587:\tlearn: 0.1346520\ttotal: 14.4s\tremaining: 10.1s\n",
      "588:\tlearn: 0.1345975\ttotal: 14.5s\tremaining: 10.1s\n",
      "589:\tlearn: 0.1345612\ttotal: 14.5s\tremaining: 10.1s\n",
      "590:\tlearn: 0.1345178\ttotal: 14.5s\tremaining: 10.1s\n",
      "591:\tlearn: 0.1344779\ttotal: 14.6s\tremaining: 10s\n",
      "592:\tlearn: 0.1344543\ttotal: 14.6s\tremaining: 10s\n",
      "593:\tlearn: 0.1344052\ttotal: 14.6s\tremaining: 9.99s\n",
      "594:\tlearn: 0.1343767\ttotal: 14.6s\tremaining: 9.96s\n",
      "595:\tlearn: 0.1343257\ttotal: 14.7s\tremaining: 9.93s\n",
      "596:\tlearn: 0.1342726\ttotal: 14.7s\tremaining: 9.91s\n",
      "597:\tlearn: 0.1342429\ttotal: 14.7s\tremaining: 9.88s\n",
      "598:\tlearn: 0.1341758\ttotal: 14.7s\tremaining: 9.86s\n",
      "599:\tlearn: 0.1341307\ttotal: 14.8s\tremaining: 9.84s\n",
      "600:\tlearn: 0.1340804\ttotal: 14.8s\tremaining: 9.81s\n",
      "601:\tlearn: 0.1340556\ttotal: 14.8s\tremaining: 9.79s\n",
      "602:\tlearn: 0.1340216\ttotal: 14.8s\tremaining: 9.76s\n",
      "603:\tlearn: 0.1339685\ttotal: 14.9s\tremaining: 9.74s\n",
      "604:\tlearn: 0.1339293\ttotal: 14.9s\tremaining: 9.71s\n",
      "605:\tlearn: 0.1339041\ttotal: 14.9s\tremaining: 9.69s\n",
      "606:\tlearn: 0.1338736\ttotal: 14.9s\tremaining: 9.66s\n",
      "607:\tlearn: 0.1338361\ttotal: 14.9s\tremaining: 9.64s\n",
      "608:\tlearn: 0.1337929\ttotal: 15s\tremaining: 9.61s\n",
      "609:\tlearn: 0.1337314\ttotal: 15s\tremaining: 9.59s\n",
      "610:\tlearn: 0.1336751\ttotal: 15s\tremaining: 9.57s\n",
      "611:\tlearn: 0.1336274\ttotal: 15s\tremaining: 9.54s\n",
      "612:\tlearn: 0.1335628\ttotal: 15.1s\tremaining: 9.51s\n",
      "613:\tlearn: 0.1334967\ttotal: 15.1s\tremaining: 9.49s\n",
      "614:\tlearn: 0.1334475\ttotal: 15.1s\tremaining: 9.46s\n",
      "615:\tlearn: 0.1333757\ttotal: 15.1s\tremaining: 9.44s\n",
      "616:\tlearn: 0.1333164\ttotal: 15.2s\tremaining: 9.42s\n",
      "617:\tlearn: 0.1332633\ttotal: 15.2s\tremaining: 9.39s\n",
      "618:\tlearn: 0.1332258\ttotal: 15.2s\tremaining: 9.36s\n",
      "619:\tlearn: 0.1331888\ttotal: 15.2s\tremaining: 9.34s\n",
      "620:\tlearn: 0.1331223\ttotal: 15.3s\tremaining: 9.31s\n",
      "621:\tlearn: 0.1330833\ttotal: 15.3s\tremaining: 9.29s\n",
      "622:\tlearn: 0.1330539\ttotal: 15.3s\tremaining: 9.27s\n",
      "623:\tlearn: 0.1330031\ttotal: 15.3s\tremaining: 9.24s\n",
      "624:\tlearn: 0.1329475\ttotal: 15.4s\tremaining: 9.21s\n",
      "625:\tlearn: 0.1329132\ttotal: 15.4s\tremaining: 9.19s\n",
      "626:\tlearn: 0.1328598\ttotal: 15.4s\tremaining: 9.17s\n",
      "627:\tlearn: 0.1328013\ttotal: 15.4s\tremaining: 9.14s\n",
      "628:\tlearn: 0.1327324\ttotal: 15.5s\tremaining: 9.12s\n",
      "629:\tlearn: 0.1326878\ttotal: 15.5s\tremaining: 9.09s\n",
      "630:\tlearn: 0.1326421\ttotal: 15.5s\tremaining: 9.07s\n",
      "631:\tlearn: 0.1325896\ttotal: 15.5s\tremaining: 9.04s\n",
      "632:\tlearn: 0.1325616\ttotal: 15.5s\tremaining: 9.02s\n",
      "633:\tlearn: 0.1324933\ttotal: 15.6s\tremaining: 8.99s\n",
      "634:\tlearn: 0.1324162\ttotal: 15.6s\tremaining: 8.97s\n",
      "635:\tlearn: 0.1323733\ttotal: 15.6s\tremaining: 8.95s\n",
      "636:\tlearn: 0.1323321\ttotal: 15.7s\tremaining: 8.93s\n",
      "637:\tlearn: 0.1322886\ttotal: 15.7s\tremaining: 8.91s\n",
      "638:\tlearn: 0.1322390\ttotal: 15.7s\tremaining: 8.88s\n",
      "639:\tlearn: 0.1321893\ttotal: 15.7s\tremaining: 8.86s\n",
      "640:\tlearn: 0.1321081\ttotal: 15.8s\tremaining: 8.83s\n",
      "641:\tlearn: 0.1320657\ttotal: 15.8s\tremaining: 8.81s\n",
      "642:\tlearn: 0.1320164\ttotal: 15.8s\tremaining: 8.79s\n",
      "643:\tlearn: 0.1319878\ttotal: 15.9s\tremaining: 8.76s\n",
      "644:\tlearn: 0.1319616\ttotal: 15.9s\tremaining: 8.74s\n",
      "645:\tlearn: 0.1319247\ttotal: 15.9s\tremaining: 8.71s\n",
      "646:\tlearn: 0.1318941\ttotal: 15.9s\tremaining: 8.69s\n",
      "647:\tlearn: 0.1318501\ttotal: 15.9s\tremaining: 8.66s\n",
      "648:\tlearn: 0.1317966\ttotal: 16s\tremaining: 8.64s\n",
      "649:\tlearn: 0.1317010\ttotal: 16s\tremaining: 8.61s\n",
      "650:\tlearn: 0.1316583\ttotal: 16s\tremaining: 8.59s\n",
      "651:\tlearn: 0.1316274\ttotal: 16s\tremaining: 8.56s\n",
      "652:\tlearn: 0.1315541\ttotal: 16.1s\tremaining: 8.54s\n",
      "653:\tlearn: 0.1314937\ttotal: 16.1s\tremaining: 8.51s\n",
      "654:\tlearn: 0.1314522\ttotal: 16.1s\tremaining: 8.49s\n",
      "655:\tlearn: 0.1313984\ttotal: 16.1s\tremaining: 8.46s\n",
      "656:\tlearn: 0.1312504\ttotal: 16.2s\tremaining: 8.43s\n",
      "657:\tlearn: 0.1312035\ttotal: 16.2s\tremaining: 8.41s\n",
      "658:\tlearn: 0.1311730\ttotal: 16.2s\tremaining: 8.38s\n",
      "659:\tlearn: 0.1311104\ttotal: 16.2s\tremaining: 8.36s\n",
      "660:\tlearn: 0.1310574\ttotal: 16.3s\tremaining: 8.33s\n",
      "661:\tlearn: 0.1310310\ttotal: 16.3s\tremaining: 8.31s\n",
      "662:\tlearn: 0.1309969\ttotal: 16.3s\tremaining: 8.28s\n",
      "663:\tlearn: 0.1309514\ttotal: 16.3s\tremaining: 8.26s\n",
      "664:\tlearn: 0.1308882\ttotal: 16.3s\tremaining: 8.23s\n",
      "665:\tlearn: 0.1308594\ttotal: 16.4s\tremaining: 8.21s\n",
      "666:\tlearn: 0.1308243\ttotal: 16.4s\tremaining: 8.18s\n",
      "667:\tlearn: 0.1307866\ttotal: 16.4s\tremaining: 8.15s\n",
      "668:\tlearn: 0.1307514\ttotal: 16.4s\tremaining: 8.13s\n",
      "669:\tlearn: 0.1307078\ttotal: 16.4s\tremaining: 8.1s\n",
      "670:\tlearn: 0.1306732\ttotal: 16.5s\tremaining: 8.07s\n",
      "671:\tlearn: 0.1306420\ttotal: 16.5s\tremaining: 8.05s\n",
      "672:\tlearn: 0.1305775\ttotal: 16.5s\tremaining: 8.03s\n",
      "673:\tlearn: 0.1305307\ttotal: 16.5s\tremaining: 8s\n",
      "674:\tlearn: 0.1304721\ttotal: 16.6s\tremaining: 7.97s\n",
      "675:\tlearn: 0.1304155\ttotal: 16.6s\tremaining: 7.95s\n",
      "676:\tlearn: 0.1303735\ttotal: 16.6s\tremaining: 7.92s\n",
      "677:\tlearn: 0.1303424\ttotal: 16.6s\tremaining: 7.9s\n",
      "678:\tlearn: 0.1302815\ttotal: 16.6s\tremaining: 7.87s\n",
      "679:\tlearn: 0.1302318\ttotal: 16.7s\tremaining: 7.84s\n",
      "680:\tlearn: 0.1301754\ttotal: 16.7s\tremaining: 7.82s\n",
      "681:\tlearn: 0.1301473\ttotal: 16.7s\tremaining: 7.8s\n",
      "682:\tlearn: 0.1300896\ttotal: 16.7s\tremaining: 7.77s\n",
      "683:\tlearn: 0.1300486\ttotal: 16.8s\tremaining: 7.75s\n",
      "684:\tlearn: 0.1300221\ttotal: 16.8s\tremaining: 7.72s\n",
      "685:\tlearn: 0.1299776\ttotal: 16.8s\tremaining: 7.69s\n",
      "686:\tlearn: 0.1299377\ttotal: 16.8s\tremaining: 7.67s\n",
      "687:\tlearn: 0.1298786\ttotal: 16.9s\tremaining: 7.64s\n",
      "688:\tlearn: 0.1298541\ttotal: 16.9s\tremaining: 7.62s\n",
      "689:\tlearn: 0.1298187\ttotal: 16.9s\tremaining: 7.59s\n",
      "690:\tlearn: 0.1297839\ttotal: 16.9s\tremaining: 7.57s\n",
      "691:\tlearn: 0.1297137\ttotal: 17s\tremaining: 7.57s\n",
      "692:\tlearn: 0.1296692\ttotal: 17.1s\tremaining: 7.56s\n",
      "693:\tlearn: 0.1296133\ttotal: 17.2s\tremaining: 7.56s\n",
      "694:\tlearn: 0.1295680\ttotal: 17.2s\tremaining: 7.54s\n",
      "695:\tlearn: 0.1295366\ttotal: 17.2s\tremaining: 7.51s\n",
      "696:\tlearn: 0.1295095\ttotal: 17.2s\tremaining: 7.48s\n",
      "697:\tlearn: 0.1294770\ttotal: 17.2s\tremaining: 7.46s\n",
      "698:\tlearn: 0.1294253\ttotal: 17.3s\tremaining: 7.43s\n",
      "699:\tlearn: 0.1293869\ttotal: 17.3s\tremaining: 7.4s\n",
      "700:\tlearn: 0.1293530\ttotal: 17.3s\tremaining: 7.38s\n",
      "701:\tlearn: 0.1293208\ttotal: 17.3s\tremaining: 7.35s\n",
      "702:\tlearn: 0.1292688\ttotal: 17.3s\tremaining: 7.33s\n",
      "703:\tlearn: 0.1292145\ttotal: 17.4s\tremaining: 7.3s\n",
      "704:\tlearn: 0.1291752\ttotal: 17.4s\tremaining: 7.28s\n",
      "705:\tlearn: 0.1291483\ttotal: 17.4s\tremaining: 7.25s\n",
      "706:\tlearn: 0.1290898\ttotal: 17.4s\tremaining: 7.22s\n",
      "707:\tlearn: 0.1290541\ttotal: 17.5s\tremaining: 7.2s\n",
      "708:\tlearn: 0.1290113\ttotal: 17.5s\tremaining: 7.17s\n",
      "709:\tlearn: 0.1289619\ttotal: 17.5s\tremaining: 7.15s\n",
      "710:\tlearn: 0.1288936\ttotal: 17.5s\tremaining: 7.12s\n",
      "711:\tlearn: 0.1288628\ttotal: 17.5s\tremaining: 7.09s\n",
      "712:\tlearn: 0.1288244\ttotal: 17.6s\tremaining: 7.07s\n",
      "713:\tlearn: 0.1287899\ttotal: 17.6s\tremaining: 7.04s\n",
      "714:\tlearn: 0.1287074\ttotal: 17.6s\tremaining: 7.02s\n",
      "715:\tlearn: 0.1286635\ttotal: 17.6s\tremaining: 6.99s\n",
      "716:\tlearn: 0.1286068\ttotal: 17.7s\tremaining: 6.97s\n",
      "717:\tlearn: 0.1285664\ttotal: 17.7s\tremaining: 6.94s\n",
      "718:\tlearn: 0.1285313\ttotal: 17.7s\tremaining: 6.92s\n",
      "719:\tlearn: 0.1284937\ttotal: 17.7s\tremaining: 6.89s\n",
      "720:\tlearn: 0.1284196\ttotal: 17.7s\tremaining: 6.87s\n",
      "721:\tlearn: 0.1283782\ttotal: 17.8s\tremaining: 6.84s\n",
      "722:\tlearn: 0.1283498\ttotal: 17.8s\tremaining: 6.82s\n",
      "723:\tlearn: 0.1283214\ttotal: 17.8s\tremaining: 6.8s\n",
      "724:\tlearn: 0.1282677\ttotal: 17.9s\tremaining: 6.78s\n",
      "725:\tlearn: 0.1282078\ttotal: 17.9s\tremaining: 6.75s\n",
      "726:\tlearn: 0.1281856\ttotal: 17.9s\tremaining: 6.73s\n",
      "727:\tlearn: 0.1281431\ttotal: 17.9s\tremaining: 6.7s\n",
      "728:\tlearn: 0.1281068\ttotal: 18s\tremaining: 6.67s\n",
      "729:\tlearn: 0.1280520\ttotal: 18s\tremaining: 6.65s\n",
      "730:\tlearn: 0.1280173\ttotal: 18s\tremaining: 6.63s\n",
      "731:\tlearn: 0.1279642\ttotal: 18s\tremaining: 6.6s\n",
      "732:\tlearn: 0.1279161\ttotal: 18.1s\tremaining: 6.58s\n",
      "733:\tlearn: 0.1278726\ttotal: 18.1s\tremaining: 6.55s\n",
      "734:\tlearn: 0.1278087\ttotal: 18.1s\tremaining: 6.53s\n",
      "735:\tlearn: 0.1277878\ttotal: 18.1s\tremaining: 6.5s\n",
      "736:\tlearn: 0.1277327\ttotal: 18.1s\tremaining: 6.48s\n",
      "737:\tlearn: 0.1276956\ttotal: 18.2s\tremaining: 6.45s\n",
      "738:\tlearn: 0.1276508\ttotal: 18.2s\tremaining: 6.42s\n",
      "739:\tlearn: 0.1276157\ttotal: 18.2s\tremaining: 6.4s\n",
      "740:\tlearn: 0.1275804\ttotal: 18.2s\tremaining: 6.37s\n",
      "741:\tlearn: 0.1275238\ttotal: 18.3s\tremaining: 6.35s\n",
      "742:\tlearn: 0.1274862\ttotal: 18.3s\tremaining: 6.33s\n",
      "743:\tlearn: 0.1274391\ttotal: 18.3s\tremaining: 6.3s\n",
      "744:\tlearn: 0.1273883\ttotal: 18.3s\tremaining: 6.28s\n",
      "745:\tlearn: 0.1273221\ttotal: 18.4s\tremaining: 6.25s\n",
      "746:\tlearn: 0.1272785\ttotal: 18.4s\tremaining: 6.22s\n",
      "747:\tlearn: 0.1272480\ttotal: 18.4s\tremaining: 6.2s\n",
      "748:\tlearn: 0.1272181\ttotal: 18.4s\tremaining: 6.17s\n",
      "749:\tlearn: 0.1271533\ttotal: 18.5s\tremaining: 6.15s\n",
      "750:\tlearn: 0.1271143\ttotal: 18.5s\tremaining: 6.13s\n",
      "751:\tlearn: 0.1270858\ttotal: 18.5s\tremaining: 6.1s\n",
      "752:\tlearn: 0.1270262\ttotal: 18.5s\tremaining: 6.08s\n",
      "753:\tlearn: 0.1269826\ttotal: 18.6s\tremaining: 6.05s\n",
      "754:\tlearn: 0.1269394\ttotal: 18.6s\tremaining: 6.03s\n",
      "755:\tlearn: 0.1269149\ttotal: 18.6s\tremaining: 6s\n",
      "756:\tlearn: 0.1268773\ttotal: 18.6s\tremaining: 5.98s\n",
      "757:\tlearn: 0.1268518\ttotal: 18.7s\tremaining: 5.96s\n",
      "758:\tlearn: 0.1268025\ttotal: 18.7s\tremaining: 5.93s\n",
      "759:\tlearn: 0.1267731\ttotal: 18.7s\tremaining: 5.91s\n",
      "760:\tlearn: 0.1267248\ttotal: 18.7s\tremaining: 5.88s\n",
      "761:\tlearn: 0.1266911\ttotal: 18.8s\tremaining: 5.86s\n",
      "762:\tlearn: 0.1266408\ttotal: 18.8s\tremaining: 5.84s\n",
      "763:\tlearn: 0.1266045\ttotal: 18.8s\tremaining: 5.81s\n",
      "764:\tlearn: 0.1265739\ttotal: 18.8s\tremaining: 5.79s\n",
      "765:\tlearn: 0.1265411\ttotal: 18.9s\tremaining: 5.76s\n",
      "766:\tlearn: 0.1264953\ttotal: 18.9s\tremaining: 5.74s\n",
      "767:\tlearn: 0.1264655\ttotal: 18.9s\tremaining: 5.72s\n",
      "768:\tlearn: 0.1264245\ttotal: 19s\tremaining: 5.69s\n",
      "769:\tlearn: 0.1263950\ttotal: 19s\tremaining: 5.67s\n",
      "770:\tlearn: 0.1263597\ttotal: 19s\tremaining: 5.64s\n",
      "771:\tlearn: 0.1263161\ttotal: 19s\tremaining: 5.62s\n",
      "772:\tlearn: 0.1262562\ttotal: 19.1s\tremaining: 5.59s\n",
      "773:\tlearn: 0.1262210\ttotal: 19.1s\tremaining: 5.57s\n",
      "774:\tlearn: 0.1261749\ttotal: 19.1s\tremaining: 5.54s\n",
      "775:\tlearn: 0.1261397\ttotal: 19.1s\tremaining: 5.52s\n",
      "776:\tlearn: 0.1260561\ttotal: 19.1s\tremaining: 5.49s\n",
      "777:\tlearn: 0.1260171\ttotal: 19.2s\tremaining: 5.47s\n",
      "778:\tlearn: 0.1259472\ttotal: 19.2s\tremaining: 5.44s\n",
      "779:\tlearn: 0.1258870\ttotal: 19.2s\tremaining: 5.42s\n",
      "780:\tlearn: 0.1258640\ttotal: 19.2s\tremaining: 5.39s\n",
      "781:\tlearn: 0.1258298\ttotal: 19.3s\tremaining: 5.37s\n",
      "782:\tlearn: 0.1257885\ttotal: 19.3s\tremaining: 5.34s\n",
      "783:\tlearn: 0.1257600\ttotal: 19.3s\tremaining: 5.32s\n",
      "784:\tlearn: 0.1257220\ttotal: 19.3s\tremaining: 5.29s\n",
      "785:\tlearn: 0.1256999\ttotal: 19.4s\tremaining: 5.27s\n",
      "786:\tlearn: 0.1256740\ttotal: 19.4s\tremaining: 5.25s\n",
      "787:\tlearn: 0.1256442\ttotal: 19.4s\tremaining: 5.22s\n",
      "788:\tlearn: 0.1256082\ttotal: 19.4s\tremaining: 5.2s\n",
      "789:\tlearn: 0.1255606\ttotal: 19.5s\tremaining: 5.17s\n",
      "790:\tlearn: 0.1255247\ttotal: 19.5s\tremaining: 5.15s\n",
      "791:\tlearn: 0.1254863\ttotal: 19.5s\tremaining: 5.12s\n",
      "792:\tlearn: 0.1254582\ttotal: 19.5s\tremaining: 5.1s\n",
      "793:\tlearn: 0.1254327\ttotal: 19.5s\tremaining: 5.07s\n",
      "794:\tlearn: 0.1253546\ttotal: 19.6s\tremaining: 5.05s\n",
      "795:\tlearn: 0.1252930\ttotal: 19.6s\tremaining: 5.02s\n",
      "796:\tlearn: 0.1252606\ttotal: 19.6s\tremaining: 5s\n",
      "797:\tlearn: 0.1252136\ttotal: 19.6s\tremaining: 4.97s\n",
      "798:\tlearn: 0.1251721\ttotal: 19.7s\tremaining: 4.95s\n",
      "799:\tlearn: 0.1251189\ttotal: 19.7s\tremaining: 4.92s\n",
      "800:\tlearn: 0.1250717\ttotal: 19.7s\tremaining: 4.9s\n",
      "801:\tlearn: 0.1250459\ttotal: 19.7s\tremaining: 4.87s\n",
      "802:\tlearn: 0.1249987\ttotal: 19.8s\tremaining: 4.85s\n",
      "803:\tlearn: 0.1249576\ttotal: 19.8s\tremaining: 4.83s\n",
      "804:\tlearn: 0.1248959\ttotal: 19.8s\tremaining: 4.8s\n",
      "805:\tlearn: 0.1248688\ttotal: 19.8s\tremaining: 4.77s\n",
      "806:\tlearn: 0.1248090\ttotal: 19.9s\tremaining: 4.75s\n",
      "807:\tlearn: 0.1247646\ttotal: 19.9s\tremaining: 4.72s\n",
      "808:\tlearn: 0.1247213\ttotal: 19.9s\tremaining: 4.7s\n",
      "809:\tlearn: 0.1246812\ttotal: 19.9s\tremaining: 4.68s\n",
      "810:\tlearn: 0.1246444\ttotal: 20s\tremaining: 4.67s\n",
      "811:\tlearn: 0.1246037\ttotal: 20.1s\tremaining: 4.65s\n",
      "812:\tlearn: 0.1245811\ttotal: 20.1s\tremaining: 4.62s\n",
      "813:\tlearn: 0.1245511\ttotal: 20.1s\tremaining: 4.6s\n",
      "814:\tlearn: 0.1245136\ttotal: 20.1s\tremaining: 4.57s\n",
      "815:\tlearn: 0.1244471\ttotal: 20.2s\tremaining: 4.55s\n",
      "816:\tlearn: 0.1244065\ttotal: 20.2s\tremaining: 4.52s\n",
      "817:\tlearn: 0.1243684\ttotal: 20.2s\tremaining: 4.5s\n",
      "818:\tlearn: 0.1243275\ttotal: 20.2s\tremaining: 4.47s\n",
      "819:\tlearn: 0.1242732\ttotal: 20.2s\tremaining: 4.45s\n",
      "820:\tlearn: 0.1242383\ttotal: 20.3s\tremaining: 4.42s\n",
      "821:\tlearn: 0.1242031\ttotal: 20.3s\tremaining: 4.39s\n",
      "822:\tlearn: 0.1241530\ttotal: 20.3s\tremaining: 4.37s\n",
      "823:\tlearn: 0.1241016\ttotal: 20.3s\tremaining: 4.34s\n",
      "824:\tlearn: 0.1240586\ttotal: 20.4s\tremaining: 4.32s\n",
      "825:\tlearn: 0.1240268\ttotal: 20.4s\tremaining: 4.29s\n",
      "826:\tlearn: 0.1239489\ttotal: 20.4s\tremaining: 4.27s\n",
      "827:\tlearn: 0.1239129\ttotal: 20.4s\tremaining: 4.24s\n",
      "828:\tlearn: 0.1238860\ttotal: 20.4s\tremaining: 4.22s\n",
      "829:\tlearn: 0.1238515\ttotal: 20.5s\tremaining: 4.19s\n",
      "830:\tlearn: 0.1238275\ttotal: 20.5s\tremaining: 4.17s\n",
      "831:\tlearn: 0.1237812\ttotal: 20.5s\tremaining: 4.14s\n",
      "832:\tlearn: 0.1237539\ttotal: 20.5s\tremaining: 4.12s\n",
      "833:\tlearn: 0.1237073\ttotal: 20.6s\tremaining: 4.09s\n",
      "834:\tlearn: 0.1236638\ttotal: 20.6s\tremaining: 4.07s\n",
      "835:\tlearn: 0.1236257\ttotal: 20.6s\tremaining: 4.04s\n",
      "836:\tlearn: 0.1235971\ttotal: 20.6s\tremaining: 4.02s\n",
      "837:\tlearn: 0.1235600\ttotal: 20.7s\tremaining: 3.99s\n",
      "838:\tlearn: 0.1235266\ttotal: 20.7s\tremaining: 3.97s\n",
      "839:\tlearn: 0.1234828\ttotal: 20.7s\tremaining: 3.94s\n",
      "840:\tlearn: 0.1234509\ttotal: 20.7s\tremaining: 3.92s\n",
      "841:\tlearn: 0.1233910\ttotal: 20.8s\tremaining: 3.89s\n",
      "842:\tlearn: 0.1233559\ttotal: 20.8s\tremaining: 3.87s\n",
      "843:\tlearn: 0.1233275\ttotal: 20.8s\tremaining: 3.84s\n",
      "844:\tlearn: 0.1232695\ttotal: 20.8s\tremaining: 3.82s\n",
      "845:\tlearn: 0.1232334\ttotal: 20.8s\tremaining: 3.79s\n",
      "846:\tlearn: 0.1231929\ttotal: 20.9s\tremaining: 3.77s\n",
      "847:\tlearn: 0.1231365\ttotal: 20.9s\tremaining: 3.74s\n",
      "848:\tlearn: 0.1231084\ttotal: 20.9s\tremaining: 3.72s\n",
      "849:\tlearn: 0.1230703\ttotal: 20.9s\tremaining: 3.69s\n",
      "850:\tlearn: 0.1230326\ttotal: 20.9s\tremaining: 3.67s\n",
      "851:\tlearn: 0.1230138\ttotal: 21s\tremaining: 3.64s\n",
      "852:\tlearn: 0.1229838\ttotal: 21s\tremaining: 3.62s\n",
      "853:\tlearn: 0.1229295\ttotal: 21s\tremaining: 3.59s\n",
      "854:\tlearn: 0.1228950\ttotal: 21s\tremaining: 3.56s\n",
      "855:\tlearn: 0.1228560\ttotal: 21s\tremaining: 3.54s\n",
      "856:\tlearn: 0.1228239\ttotal: 21.1s\tremaining: 3.52s\n",
      "857:\tlearn: 0.1227887\ttotal: 21.1s\tremaining: 3.49s\n",
      "858:\tlearn: 0.1227391\ttotal: 21.1s\tremaining: 3.46s\n",
      "859:\tlearn: 0.1226943\ttotal: 21.1s\tremaining: 3.44s\n",
      "860:\tlearn: 0.1226415\ttotal: 21.2s\tremaining: 3.42s\n",
      "861:\tlearn: 0.1225878\ttotal: 21.2s\tremaining: 3.39s\n",
      "862:\tlearn: 0.1225176\ttotal: 21.2s\tremaining: 3.37s\n",
      "863:\tlearn: 0.1224655\ttotal: 21.2s\tremaining: 3.34s\n",
      "864:\tlearn: 0.1224180\ttotal: 21.3s\tremaining: 3.32s\n",
      "865:\tlearn: 0.1223542\ttotal: 21.3s\tremaining: 3.29s\n",
      "866:\tlearn: 0.1222973\ttotal: 21.3s\tremaining: 3.27s\n",
      "867:\tlearn: 0.1222684\ttotal: 21.3s\tremaining: 3.24s\n",
      "868:\tlearn: 0.1222339\ttotal: 21.4s\tremaining: 3.22s\n",
      "869:\tlearn: 0.1222012\ttotal: 21.4s\tremaining: 3.19s\n",
      "870:\tlearn: 0.1221792\ttotal: 21.4s\tremaining: 3.17s\n",
      "871:\tlearn: 0.1221355\ttotal: 21.4s\tremaining: 3.15s\n",
      "872:\tlearn: 0.1221070\ttotal: 21.5s\tremaining: 3.12s\n",
      "873:\tlearn: 0.1220400\ttotal: 21.5s\tremaining: 3.1s\n",
      "874:\tlearn: 0.1220147\ttotal: 21.5s\tremaining: 3.07s\n",
      "875:\tlearn: 0.1219622\ttotal: 21.5s\tremaining: 3.05s\n",
      "876:\tlearn: 0.1219224\ttotal: 21.6s\tremaining: 3.02s\n",
      "877:\tlearn: 0.1218902\ttotal: 21.6s\tremaining: 3s\n",
      "878:\tlearn: 0.1218429\ttotal: 21.6s\tremaining: 2.98s\n",
      "879:\tlearn: 0.1218272\ttotal: 21.6s\tremaining: 2.95s\n",
      "880:\tlearn: 0.1217777\ttotal: 21.7s\tremaining: 2.93s\n",
      "881:\tlearn: 0.1217174\ttotal: 21.7s\tremaining: 2.9s\n",
      "882:\tlearn: 0.1216601\ttotal: 21.7s\tremaining: 2.88s\n",
      "883:\tlearn: 0.1216176\ttotal: 21.7s\tremaining: 2.85s\n",
      "884:\tlearn: 0.1215888\ttotal: 21.8s\tremaining: 2.83s\n",
      "885:\tlearn: 0.1215461\ttotal: 21.8s\tremaining: 2.81s\n",
      "886:\tlearn: 0.1215140\ttotal: 21.8s\tremaining: 2.78s\n",
      "887:\tlearn: 0.1214910\ttotal: 21.8s\tremaining: 2.75s\n",
      "888:\tlearn: 0.1214343\ttotal: 21.9s\tremaining: 2.73s\n",
      "889:\tlearn: 0.1213297\ttotal: 21.9s\tremaining: 2.71s\n",
      "890:\tlearn: 0.1213008\ttotal: 21.9s\tremaining: 2.68s\n",
      "891:\tlearn: 0.1212615\ttotal: 22s\tremaining: 2.66s\n",
      "892:\tlearn: 0.1212086\ttotal: 22s\tremaining: 2.63s\n",
      "893:\tlearn: 0.1211786\ttotal: 22s\tremaining: 2.61s\n",
      "894:\tlearn: 0.1211381\ttotal: 22s\tremaining: 2.58s\n",
      "895:\tlearn: 0.1210997\ttotal: 22.1s\tremaining: 2.56s\n",
      "896:\tlearn: 0.1210569\ttotal: 22.1s\tremaining: 2.54s\n",
      "897:\tlearn: 0.1210264\ttotal: 22.1s\tremaining: 2.51s\n",
      "898:\tlearn: 0.1209881\ttotal: 22.1s\tremaining: 2.48s\n",
      "899:\tlearn: 0.1209577\ttotal: 22.1s\tremaining: 2.46s\n",
      "900:\tlearn: 0.1209270\ttotal: 22.2s\tremaining: 2.44s\n",
      "901:\tlearn: 0.1208888\ttotal: 22.2s\tremaining: 2.41s\n",
      "902:\tlearn: 0.1208483\ttotal: 22.2s\tremaining: 2.39s\n",
      "903:\tlearn: 0.1208029\ttotal: 22.3s\tremaining: 2.36s\n",
      "904:\tlearn: 0.1207820\ttotal: 22.3s\tremaining: 2.34s\n",
      "905:\tlearn: 0.1207468\ttotal: 22.3s\tremaining: 2.31s\n",
      "906:\tlearn: 0.1207096\ttotal: 22.3s\tremaining: 2.29s\n",
      "907:\tlearn: 0.1206659\ttotal: 22.4s\tremaining: 2.27s\n",
      "908:\tlearn: 0.1206371\ttotal: 22.4s\tremaining: 2.24s\n",
      "909:\tlearn: 0.1205941\ttotal: 22.4s\tremaining: 2.21s\n",
      "910:\tlearn: 0.1205561\ttotal: 22.4s\tremaining: 2.19s\n",
      "911:\tlearn: 0.1205128\ttotal: 22.5s\tremaining: 2.17s\n",
      "912:\tlearn: 0.1204562\ttotal: 22.5s\tremaining: 2.14s\n",
      "913:\tlearn: 0.1204235\ttotal: 22.5s\tremaining: 2.12s\n",
      "914:\tlearn: 0.1203563\ttotal: 22.5s\tremaining: 2.09s\n",
      "915:\tlearn: 0.1203372\ttotal: 22.5s\tremaining: 2.07s\n",
      "916:\tlearn: 0.1203061\ttotal: 22.6s\tremaining: 2.04s\n",
      "917:\tlearn: 0.1202548\ttotal: 22.6s\tremaining: 2.02s\n",
      "918:\tlearn: 0.1202163\ttotal: 22.6s\tremaining: 1.99s\n",
      "919:\tlearn: 0.1201836\ttotal: 22.6s\tremaining: 1.97s\n",
      "920:\tlearn: 0.1201390\ttotal: 22.7s\tremaining: 1.95s\n",
      "921:\tlearn: 0.1201075\ttotal: 22.7s\tremaining: 1.92s\n",
      "922:\tlearn: 0.1200614\ttotal: 22.7s\tremaining: 1.9s\n",
      "923:\tlearn: 0.1200294\ttotal: 22.7s\tremaining: 1.87s\n",
      "924:\tlearn: 0.1199804\ttotal: 22.8s\tremaining: 1.84s\n",
      "925:\tlearn: 0.1199288\ttotal: 22.8s\tremaining: 1.82s\n",
      "926:\tlearn: 0.1199034\ttotal: 22.8s\tremaining: 1.8s\n",
      "927:\tlearn: 0.1198645\ttotal: 22.8s\tremaining: 1.77s\n",
      "928:\tlearn: 0.1198235\ttotal: 22.9s\tremaining: 1.75s\n",
      "929:\tlearn: 0.1197926\ttotal: 22.9s\tremaining: 1.72s\n",
      "930:\tlearn: 0.1197401\ttotal: 22.9s\tremaining: 1.7s\n",
      "931:\tlearn: 0.1197086\ttotal: 22.9s\tremaining: 1.67s\n",
      "932:\tlearn: 0.1196601\ttotal: 23s\tremaining: 1.65s\n",
      "933:\tlearn: 0.1196305\ttotal: 23s\tremaining: 1.62s\n",
      "934:\tlearn: 0.1196056\ttotal: 23s\tremaining: 1.6s\n",
      "935:\tlearn: 0.1195741\ttotal: 23s\tremaining: 1.57s\n",
      "936:\tlearn: 0.1195380\ttotal: 23.1s\tremaining: 1.55s\n",
      "937:\tlearn: 0.1195057\ttotal: 23.2s\tremaining: 1.53s\n",
      "938:\tlearn: 0.1194738\ttotal: 23.2s\tremaining: 1.51s\n",
      "939:\tlearn: 0.1194341\ttotal: 23.3s\tremaining: 1.49s\n",
      "940:\tlearn: 0.1193889\ttotal: 23.3s\tremaining: 1.46s\n",
      "941:\tlearn: 0.1193414\ttotal: 23.3s\tremaining: 1.44s\n",
      "942:\tlearn: 0.1193017\ttotal: 23.3s\tremaining: 1.41s\n",
      "943:\tlearn: 0.1192716\ttotal: 23.4s\tremaining: 1.39s\n",
      "944:\tlearn: 0.1192418\ttotal: 23.4s\tremaining: 1.36s\n",
      "945:\tlearn: 0.1192031\ttotal: 23.4s\tremaining: 1.34s\n",
      "946:\tlearn: 0.1191647\ttotal: 23.4s\tremaining: 1.31s\n",
      "947:\tlearn: 0.1191325\ttotal: 23.5s\tremaining: 1.29s\n",
      "948:\tlearn: 0.1190839\ttotal: 23.5s\tremaining: 1.26s\n",
      "949:\tlearn: 0.1190168\ttotal: 23.5s\tremaining: 1.24s\n",
      "950:\tlearn: 0.1189848\ttotal: 23.6s\tremaining: 1.21s\n",
      "951:\tlearn: 0.1189409\ttotal: 23.6s\tremaining: 1.19s\n",
      "952:\tlearn: 0.1189016\ttotal: 23.6s\tremaining: 1.16s\n",
      "953:\tlearn: 0.1188637\ttotal: 23.6s\tremaining: 1.14s\n",
      "954:\tlearn: 0.1188323\ttotal: 23.7s\tremaining: 1.11s\n",
      "955:\tlearn: 0.1188057\ttotal: 23.7s\tremaining: 1.09s\n",
      "956:\tlearn: 0.1187743\ttotal: 23.7s\tremaining: 1.06s\n",
      "957:\tlearn: 0.1187257\ttotal: 23.7s\tremaining: 1.04s\n",
      "958:\tlearn: 0.1187026\ttotal: 23.7s\tremaining: 1.01s\n",
      "959:\tlearn: 0.1186488\ttotal: 23.8s\tremaining: 991ms\n",
      "960:\tlearn: 0.1186181\ttotal: 23.8s\tremaining: 966ms\n",
      "961:\tlearn: 0.1185806\ttotal: 23.8s\tremaining: 941ms\n",
      "962:\tlearn: 0.1185320\ttotal: 23.8s\tremaining: 916ms\n",
      "963:\tlearn: 0.1185013\ttotal: 23.9s\tremaining: 891ms\n",
      "964:\tlearn: 0.1184791\ttotal: 23.9s\tremaining: 866ms\n",
      "965:\tlearn: 0.1184472\ttotal: 23.9s\tremaining: 842ms\n",
      "966:\tlearn: 0.1183916\ttotal: 23.9s\tremaining: 817ms\n",
      "967:\tlearn: 0.1183542\ttotal: 24s\tremaining: 792ms\n",
      "968:\tlearn: 0.1183230\ttotal: 24s\tremaining: 768ms\n",
      "969:\tlearn: 0.1182819\ttotal: 24s\tremaining: 743ms\n",
      "970:\tlearn: 0.1182676\ttotal: 24.1s\tremaining: 719ms\n",
      "971:\tlearn: 0.1182371\ttotal: 24.1s\tremaining: 694ms\n",
      "972:\tlearn: 0.1181940\ttotal: 24.1s\tremaining: 669ms\n",
      "973:\tlearn: 0.1181658\ttotal: 24.1s\tremaining: 644ms\n",
      "974:\tlearn: 0.1181330\ttotal: 24.2s\tremaining: 620ms\n",
      "975:\tlearn: 0.1180988\ttotal: 24.2s\tremaining: 595ms\n",
      "976:\tlearn: 0.1180616\ttotal: 24.2s\tremaining: 570ms\n",
      "977:\tlearn: 0.1180329\ttotal: 24.2s\tremaining: 545ms\n",
      "978:\tlearn: 0.1180105\ttotal: 24.3s\tremaining: 520ms\n",
      "979:\tlearn: 0.1179574\ttotal: 24.3s\tremaining: 496ms\n",
      "980:\tlearn: 0.1179355\ttotal: 24.3s\tremaining: 471ms\n",
      "981:\tlearn: 0.1179058\ttotal: 24.3s\tremaining: 446ms\n",
      "982:\tlearn: 0.1178703\ttotal: 24.4s\tremaining: 421ms\n",
      "983:\tlearn: 0.1178410\ttotal: 24.4s\tremaining: 396ms\n",
      "984:\tlearn: 0.1178006\ttotal: 24.4s\tremaining: 372ms\n",
      "985:\tlearn: 0.1177749\ttotal: 24.4s\tremaining: 347ms\n",
      "986:\tlearn: 0.1177514\ttotal: 24.5s\tremaining: 322ms\n",
      "987:\tlearn: 0.1177222\ttotal: 24.5s\tremaining: 297ms\n",
      "988:\tlearn: 0.1176799\ttotal: 24.5s\tremaining: 273ms\n",
      "989:\tlearn: 0.1176653\ttotal: 24.6s\tremaining: 248ms\n",
      "990:\tlearn: 0.1176154\ttotal: 24.6s\tremaining: 223ms\n",
      "991:\tlearn: 0.1175674\ttotal: 24.6s\tremaining: 198ms\n",
      "992:\tlearn: 0.1175373\ttotal: 24.6s\tremaining: 174ms\n",
      "993:\tlearn: 0.1175001\ttotal: 24.7s\tremaining: 149ms\n",
      "994:\tlearn: 0.1174791\ttotal: 24.7s\tremaining: 124ms\n",
      "995:\tlearn: 0.1174378\ttotal: 24.7s\tremaining: 99.3ms\n",
      "996:\tlearn: 0.1174155\ttotal: 24.7s\tremaining: 74.5ms\n",
      "997:\tlearn: 0.1173818\ttotal: 24.8s\tremaining: 49.6ms\n",
      "998:\tlearn: 0.1173596\ttotal: 24.8s\tremaining: 24.8ms\n",
      "999:\tlearn: 0.1173182\ttotal: 24.8s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    #create a dataframe that stores all the metrics not just the last one\n",
    "    # Initialize a list to store metrics if it doesn't exist\n",
    "    if 'metrics_list' not in locals():\n",
    "        metrics_list = []\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred).tolist()  # convert to list for DataFrame compatibility\n",
    "\n",
    "    metrics_list.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Recall\": rec,\n",
    "        \"Precision\": prec,\n",
    "        \"F1 Score\": f1,\n",
    "        \"Confusion Matrix\": cm\n",
    "    })\n",
    "\n",
    "    if name == \"XGBoost\":  # Match the exact key in your models dictionary\n",
    "        with open('xgboost_model.pkl', 'wb') as file:\n",
    "            pickle.dump(model, file)\n",
    "\n",
    "# After the loop, create the DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4953a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.893222</td>\n",
       "      <td>0.749751</td>\n",
       "      <td>0.766921</td>\n",
       "      <td>0.758239</td>\n",
       "      <td>[[6532, 458], [503, 1507]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.896556</td>\n",
       "      <td>0.785075</td>\n",
       "      <td>0.759750</td>\n",
       "      <td>0.772205</td>\n",
       "      <td>[[6491, 499], [432, 1578]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.928667</td>\n",
       "      <td>0.768657</td>\n",
       "      <td>0.897213</td>\n",
       "      <td>0.827974</td>\n",
       "      <td>[[6813, 177], [465, 1545]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.893222</td>\n",
       "      <td>0.701990</td>\n",
       "      <td>0.795826</td>\n",
       "      <td>0.745969</td>\n",
       "      <td>[[6628, 362], [599, 1411]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.891444</td>\n",
       "      <td>0.641294</td>\n",
       "      <td>0.834304</td>\n",
       "      <td>0.725176</td>\n",
       "      <td>[[6734, 256], [721, 1289]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.933556</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.891353</td>\n",
       "      <td>0.843209</td>\n",
       "      <td>[[6794, 196], [402, 1608]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.932222</td>\n",
       "      <td>0.791542</td>\n",
       "      <td>0.892817</td>\n",
       "      <td>0.839135</td>\n",
       "      <td>[[6799, 191], [419, 1591]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.932444</td>\n",
       "      <td>0.788060</td>\n",
       "      <td>0.896942</td>\n",
       "      <td>0.838983</td>\n",
       "      <td>[[6808, 182], [426, 1584]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.910667</td>\n",
       "      <td>0.765672</td>\n",
       "      <td>0.822115</td>\n",
       "      <td>0.792890</td>\n",
       "      <td>[[6657, 333], [471, 1539]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.921889</td>\n",
       "      <td>0.758706</td>\n",
       "      <td>0.874928</td>\n",
       "      <td>0.812683</td>\n",
       "      <td>[[6772, 218], [485, 1525]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.893222</td>\n",
       "      <td>0.749751</td>\n",
       "      <td>0.766921</td>\n",
       "      <td>0.758239</td>\n",
       "      <td>[[6532, 458], [503, 1507]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.895889</td>\n",
       "      <td>0.778607</td>\n",
       "      <td>0.760817</td>\n",
       "      <td>0.769609</td>\n",
       "      <td>[[6498, 492], [445, 1565]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.927556</td>\n",
       "      <td>0.768159</td>\n",
       "      <td>0.892486</td>\n",
       "      <td>0.825668</td>\n",
       "      <td>[[6804, 186], [466, 1544]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.893222</td>\n",
       "      <td>0.701990</td>\n",
       "      <td>0.795826</td>\n",
       "      <td>0.745969</td>\n",
       "      <td>[[6628, 362], [599, 1411]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.891444</td>\n",
       "      <td>0.641294</td>\n",
       "      <td>0.834304</td>\n",
       "      <td>0.725176</td>\n",
       "      <td>[[6734, 256], [721, 1289]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.933556</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.891353</td>\n",
       "      <td>0.843209</td>\n",
       "      <td>[[6794, 196], [402, 1608]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.932222</td>\n",
       "      <td>0.791542</td>\n",
       "      <td>0.892817</td>\n",
       "      <td>0.839135</td>\n",
       "      <td>[[6799, 191], [419, 1591]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.932444</td>\n",
       "      <td>0.788060</td>\n",
       "      <td>0.896942</td>\n",
       "      <td>0.838983</td>\n",
       "      <td>[[6808, 182], [426, 1584]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.910667</td>\n",
       "      <td>0.765672</td>\n",
       "      <td>0.822115</td>\n",
       "      <td>0.792890</td>\n",
       "      <td>[[6657, 333], [471, 1539]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.921889</td>\n",
       "      <td>0.758706</td>\n",
       "      <td>0.874928</td>\n",
       "      <td>0.812683</td>\n",
       "      <td>[[6772, 218], [485, 1525]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy    Recall  Precision  F1 Score  \\\n",
       "0   Logistic Regression  0.893222  0.749751   0.766921  0.758239   \n",
       "1         Decision Tree  0.896556  0.785075   0.759750  0.772205   \n",
       "2         Random Forest  0.928667  0.768657   0.897213  0.827974   \n",
       "3                   SVM  0.893222  0.701990   0.795826  0.745969   \n",
       "4                   KNN  0.891444  0.641294   0.834304  0.725176   \n",
       "5               XGBoost  0.933556  0.800000   0.891353  0.843209   \n",
       "6              LightGBM  0.932222  0.791542   0.892817  0.839135   \n",
       "7              CatBoost  0.932444  0.788060   0.896942  0.838983   \n",
       "8              AdaBoost  0.910667  0.765672   0.822115  0.792890   \n",
       "9     Gradient Boosting  0.921889  0.758706   0.874928  0.812683   \n",
       "10  Logistic Regression  0.893222  0.749751   0.766921  0.758239   \n",
       "11        Decision Tree  0.895889  0.778607   0.760817  0.769609   \n",
       "12        Random Forest  0.927556  0.768159   0.892486  0.825668   \n",
       "13                  SVM  0.893222  0.701990   0.795826  0.745969   \n",
       "14                  KNN  0.891444  0.641294   0.834304  0.725176   \n",
       "15              XGBoost  0.933556  0.800000   0.891353  0.843209   \n",
       "16             LightGBM  0.932222  0.791542   0.892817  0.839135   \n",
       "17             CatBoost  0.932444  0.788060   0.896942  0.838983   \n",
       "18             AdaBoost  0.910667  0.765672   0.822115  0.792890   \n",
       "19    Gradient Boosting  0.921889  0.758706   0.874928  0.812683   \n",
       "\n",
       "              Confusion Matrix  \n",
       "0   [[6532, 458], [503, 1507]]  \n",
       "1   [[6491, 499], [432, 1578]]  \n",
       "2   [[6813, 177], [465, 1545]]  \n",
       "3   [[6628, 362], [599, 1411]]  \n",
       "4   [[6734, 256], [721, 1289]]  \n",
       "5   [[6794, 196], [402, 1608]]  \n",
       "6   [[6799, 191], [419, 1591]]  \n",
       "7   [[6808, 182], [426, 1584]]  \n",
       "8   [[6657, 333], [471, 1539]]  \n",
       "9   [[6772, 218], [485, 1525]]  \n",
       "10  [[6532, 458], [503, 1507]]  \n",
       "11  [[6498, 492], [445, 1565]]  \n",
       "12  [[6804, 186], [466, 1544]]  \n",
       "13  [[6628, 362], [599, 1411]]  \n",
       "14  [[6734, 256], [721, 1289]]  \n",
       "15  [[6794, 196], [402, 1608]]  \n",
       "16  [[6799, 191], [419, 1591]]  \n",
       "17  [[6808, 182], [426, 1584]]  \n",
       "18  [[6657, 333], [471, 1539]]  \n",
       "19  [[6772, 218], [485, 1525]]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57e6dd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1148\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1148\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1148\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001781 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1147\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1149\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1148\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006819 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1148\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005621 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1148\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006053 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1147\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1149\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1148\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1148\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1148\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006131 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1147\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1149\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1148\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1148\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1148\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1147\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1149\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1148\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1148\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002022 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1148\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1147\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074621 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1149\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029555 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1148\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.260091 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1148\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005006 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1148\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1147\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003973 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1149\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1148\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1148\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1148\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1147\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007001 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1149\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1148\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1148\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1148\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1147\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 22408\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001931 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1149\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n",
      "[LightGBM] [Info] Number of positive: 7990, number of negative: 28010\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004749 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36000, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221944 -> initscore=-1.254371\n",
      "[LightGBM] [Info] Start training from score -1.254371\n"
     ]
    }
   ],
   "source": [
    "#hypertuning top 3 models\n",
    "\n",
    "top_models = {\n",
    "    'XGBoost': (\n",
    "        XGBClassifier(),\n",
    "        {\n",
    "            'n_estimators': [100, 200],\n",
    "            'learning_rate': [0.01, 0.1],\n",
    "            'max_depth': [3, 6, 8]\n",
    "        }\n",
    "    ),\n",
    "    'CatBoost': (\n",
    "        CatBoostClassifier(verbose=0),\n",
    "        {\n",
    "            'iterations': [100, 200],\n",
    "            'learning_rate': [0.01, 0.1],\n",
    "            'depth': [4, 6, 8]\n",
    "        }\n",
    "    ),\n",
    "    'LightGBM': (\n",
    "        LGBMClassifier(),\n",
    "        {\n",
    "            'n_estimators': [100, 200],\n",
    "            'learning_rate': [0.01, 0.1],\n",
    "            'num_leaves': [31, 50]\n",
    "        }\n",
    "    )\n",
    "}\n",
    "\n",
    "grid_list = []\n",
    "for name, (model, params) in top_models.items():\n",
    "\n",
    "    grid_model = GridSearchCV(model, params, cv=5)\n",
    "    grid_model.fit(X_train, y_train)\n",
    "    y_pred = grid_model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred).tolist()  # convert to list for DataFrame compatibility\n",
    "\n",
    "    grid_list.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Recall\": rec,\n",
    "        \"Precision\": prec,\n",
    "        \"F1 Score\": f1,\n",
    "        \"Confusion Matrix\": cm\n",
    "    })\n",
    "\n",
    "# After the loop, create the DataFrame\n",
    "grid_df = pd.DataFrame(grid_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.934556</td>\n",
       "      <td>0.800995</td>\n",
       "      <td>0.894942</td>\n",
       "      <td>0.845366</td>\n",
       "      <td>[[6801, 189], [400, 1610]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.929444</td>\n",
       "      <td>0.780597</td>\n",
       "      <td>0.889960</td>\n",
       "      <td>0.831699</td>\n",
       "      <td>[[6796, 194], [441, 1569]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.933222</td>\n",
       "      <td>0.804478</td>\n",
       "      <td>0.886027</td>\n",
       "      <td>0.843286</td>\n",
       "      <td>[[6782, 208], [393, 1617]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy    Recall  Precision  F1 Score  \\\n",
       "0   XGBoost  0.934556  0.800995   0.894942  0.845366   \n",
       "1  CatBoost  0.929444  0.780597   0.889960  0.831699   \n",
       "2  LightGBM  0.933222  0.804478   0.886027  0.843286   \n",
       "\n",
       "             Confusion Matrix  \n",
       "0  [[6801, 189], [400, 1610]]  \n",
       "1  [[6796, 194], [441, 1569]]  \n",
       "2  [[6782, 208], [393, 1617]]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.893222</td>\n",
       "      <td>0.744776</td>\n",
       "      <td>0.769666</td>\n",
       "      <td>0.757016</td>\n",
       "      <td>[[6542, 448], [513, 1497]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.896889</td>\n",
       "      <td>0.790050</td>\n",
       "      <td>0.758357</td>\n",
       "      <td>0.773879</td>\n",
       "      <td>[[6484, 506], [422, 1588]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.926444</td>\n",
       "      <td>0.761692</td>\n",
       "      <td>0.893232</td>\n",
       "      <td>0.822234</td>\n",
       "      <td>[[6807, 183], [479, 1531]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.892889</td>\n",
       "      <td>0.697512</td>\n",
       "      <td>0.797497</td>\n",
       "      <td>0.744161</td>\n",
       "      <td>[[6634, 356], [608, 1402]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.890889</td>\n",
       "      <td>0.638308</td>\n",
       "      <td>0.834200</td>\n",
       "      <td>0.723224</td>\n",
       "      <td>[[6735, 255], [727, 1283]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.934111</td>\n",
       "      <td>0.808955</td>\n",
       "      <td>0.886104</td>\n",
       "      <td>0.845774</td>\n",
       "      <td>[[6781, 209], [384, 1626]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.929556</td>\n",
       "      <td>0.786567</td>\n",
       "      <td>0.885218</td>\n",
       "      <td>0.832982</td>\n",
       "      <td>[[6785, 205], [429, 1581]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.934333</td>\n",
       "      <td>0.795025</td>\n",
       "      <td>0.899268</td>\n",
       "      <td>0.843940</td>\n",
       "      <td>[[6811, 179], [412, 1598]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.910444</td>\n",
       "      <td>0.764179</td>\n",
       "      <td>0.822270</td>\n",
       "      <td>0.792161</td>\n",
       "      <td>[[6658, 332], [474, 1536]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.920778</td>\n",
       "      <td>0.762189</td>\n",
       "      <td>0.867006</td>\n",
       "      <td>0.811226</td>\n",
       "      <td>[[6755, 235], [478, 1532]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy    Recall  Precision  F1 Score  \\\n",
       "0  Logistic Regression  0.893222  0.744776   0.769666  0.757016   \n",
       "1        Decision Tree  0.896889  0.790050   0.758357  0.773879   \n",
       "2        Random Forest  0.926444  0.761692   0.893232  0.822234   \n",
       "3                  SVM  0.892889  0.697512   0.797497  0.744161   \n",
       "4                  KNN  0.890889  0.638308   0.834200  0.723224   \n",
       "5              XGBoost  0.934111  0.808955   0.886104  0.845774   \n",
       "6             LightGBM  0.929556  0.786567   0.885218  0.832982   \n",
       "7             CatBoost  0.934333  0.795025   0.899268  0.843940   \n",
       "8             AdaBoost  0.910444  0.764179   0.822270  0.792161   \n",
       "9    Gradient Boosting  0.920778  0.762189   0.867006  0.811226   \n",
       "\n",
       "             Confusion Matrix  \n",
       "0  [[6542, 448], [513, 1497]]  \n",
       "1  [[6484, 506], [422, 1588]]  \n",
       "2  [[6807, 183], [479, 1531]]  \n",
       "3  [[6634, 356], [608, 1402]]  \n",
       "4  [[6735, 255], [727, 1283]]  \n",
       "5  [[6781, 209], [384, 1626]]  \n",
       "6  [[6785, 205], [429, 1581]]  \n",
       "7  [[6811, 179], [412, 1598]]  \n",
       "8  [[6658, 332], [474, 1536]]  \n",
       "9  [[6755, 235], [478, 1532]]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
